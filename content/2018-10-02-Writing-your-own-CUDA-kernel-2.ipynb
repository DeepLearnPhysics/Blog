{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you followed part 1 of the tutorial, you now understand how to write the CUDA kernel itself. However it would be even better if you could use it directly in your Tensorflow or PyTorch program. In this part of the tutorial we show how to do it in Tensorflow. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to integrate this new CUDA kernel to our network we have to wrap it into a new TensorFlow operation. The [official documentation](https://www.tensorflow.org/extend/adding_an_op#gpu_kernels) on this point is pretty poor and full of mistakes. We will end up with 3 new files:\n",
    "* `crop_op.h` header file\n",
    "* `crop_op.cc` Registers the new TF operation and CPU/GPU kernels. Defines CPU implementation and OpKernel.\n",
    "* `crop_op.cu.cc` Defines GPU kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `crop_op.h`\n",
    "This is the headers file, it contains 2 definitions:\n",
    "```cpp\n",
    "#ifndef CROP_OP_H_\n",
    "#define CROP_OP_H_\n",
    "\n",
    "#include \"tensorflow/core/framework/op_kernel.h\"\n",
    "#include <iostream>\n",
    "\n",
    "using namespace tensorflow;\n",
    "\n",
    "template <typename Device, typename T>\n",
    "struct CropFunctor {\n",
    "  void operator()(\n",
    "    const Device& d,\n",
    "    const T* image_ptr,\n",
    "    const int* crop_centers_ptr,\n",
    "    int crop_size,\n",
    "    int image_size,\n",
    "    int channels,\n",
    "    int num_crops,\n",
    "    T* crops_ptr\n",
    "  );\n",
    "};\n",
    "```\n",
    "We define here a general version of `CropFunctor` which will run on CPU.\n",
    "```cpp\n",
    "#if GOOGLE_CUDA\n",
    "// Partially specialize functor for GpuDevice.\n",
    "template <typename T>\n",
    "struct CropFunctor<Eigen::GpuDevice, T> {\n",
    "  void operator()(\n",
    "    const Eigen::GpuDevice& d,\n",
    "    const T* image_ptr,\n",
    "    const int* crop_centers_ptr,\n",
    "    int crop_size,\n",
    "    int image_size,\n",
    "    int channels,\n",
    "    int num_crops,\n",
    "    T* crops_ptr\n",
    "  );\n",
    "};\n",
    "#endif\n",
    "\n",
    "#endif // CROP_OP_H_\n",
    "```\n",
    "This partially specialized version of `CropFunctor` will run on GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `crop_op.cc`\n",
    "Moving on to `crop_op.cc`, we have the registration of the new TF operation called `Crop` and of all its arguments:\n",
    "```cpp\n",
    "#include \"crop_op.h\"\n",
    "\n",
    "using namespace tensorflow;\n",
    "\n",
    "// Register TF operation\n",
    "REGISTER_OP(\"Crop\")\n",
    "    .Attr(\"T: {float, int32} = DT_FLOAT\")\n",
    "    .Input(\"image: float32\")\n",
    "    .Input(\"crop_centers: int32\")\n",
    "    .Input(\"crop_size: int32\")\n",
    "    .Output(\"crops: float32\");\n",
    "\n",
    "using CPUDevice = Eigen::ThreadPoolDevice;\n",
    "using GPUDevice = Eigen::GpuDevice;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define an (empty) CPU implementation of `CropFunctor`.\n",
    "```cpp\n",
    "// CPU specialization of actual computation.\n",
    "template <typename T>\n",
    "struct CropFunctor<CPUDevice, T> {\n",
    "  void operator()(\n",
    "    const CPUDevice& d,\n",
    "    const T* image_ptr,\n",
    "    const int* crop_centers_ptr,\n",
    "    int crop_size,\n",
    "    int image_size,\n",
    "    int channels,\n",
    "    int num_crops,\n",
    "    T* crops_ptr\n",
    "  ) {\n",
    "\n",
    "  }\n",
    "};\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define the `OpKernel` which will interface between TF and the `CropFunctor` functions.\n",
    "```cpp\n",
    "// OpKernel definition.\n",
    "// template parameter <T> is the datatype of the tensors.\n",
    "template <typename Device, typename T>\n",
    "class CropOp : public OpKernel {\n",
    " public:\n",
    "  explicit CropOp(OpKernelConstruction* context) : OpKernel(context) {}\n",
    "\n",
    "  void Compute(OpKernelContext* context) override {\n",
    "```\n",
    "We can grab the input data, crop centers and crop size through `context->input`.\n",
    "```cpp\n",
    "    // Grab the input tensors\n",
    "    const Tensor& image = context->input(0);\n",
    "    const Tensor& crop_centers = context->input(1);\n",
    "    const Tensor& crop_size_tensor = context->input(2);\n",
    "    // FIXME\n",
    "    OP_REQUIRES(context, TensorShapeUtils::IsScalar(crop_size_tensor.shape()), errors::InvalidArgument(\"crop_size must be scalar, has shape \", crop_size_tensor.shape().DebugString()));\n",
    "    //const int crop_size = crop_size_tensor.scalar<int32>()();\n",
    "    const int crop_size = 64;\n",
    "```\n",
    " We define the output array and its shape:\n",
    "```cpp\n",
    "    // Get shapes of input tensors\n",
    "    const TensorShape& image_shape = image.shape();\n",
    "    const TensorShape& crop_centers_shape = crop_centers.shape();\n",
    "    int image_size = image_shape.dim_size(1);\n",
    "    int channels = image_shape.dim_size(3);\n",
    "    int num_crops = crop_centers_shape.dim_size(0);\n",
    "    int dim = crop_centers_shape.dim_size(1);\n",
    "\n",
    "    // Create an output tensor\n",
    "    Tensor* crops = NULL;\n",
    "    // create output shape\n",
    "    TensorShape crops_shape;\n",
    "    crops_shape.AddDim(num_crops);\n",
    "    crops_shape.AddDim(crop_size);\n",
    "    crops_shape.AddDim(crop_size);\n",
    "    crops_shape.AddDim(crop_size);\n",
    "    crops_shape.AddDim(channels);\n",
    "    OP_REQUIRES_OK(context, context->allocate_output(0, crops_shape,\n",
    "                                                     &crops));\n",
    "```\n",
    "Finally `CropFunctor` is called.\n",
    "```cpp\n",
    "    // Do the computation.\n",
    "    CropFunctor<Device, T>()(\n",
    "        context->eigen_device<Device>(),\n",
    "        image.flat<T>().data(),\n",
    "        crop_centers.flat<int>().data(),\n",
    "        crop_size,\n",
    "        image_size,\n",
    "        channels,\n",
    "        num_crops,\n",
    "        crops->flat<T>().data()\n",
    "      );\n",
    "\n",
    "  }\n",
    "};\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last thing in `crop_op.cc`, we register our CPU and GPU kernels with TensorFlow.\n",
    "```cpp\n",
    "// Register the CPU kernels.\n",
    "#define REGISTER_CPU(T) \\\n",
    "  REGISTER_KERNEL_BUILDER( \\\n",
    "      Name(\"Crop\") \\\n",
    "      .Device(DEVICE_CPU) \\\n",
    "      .TypeConstraint<T>(\"T\"), \\\n",
    "    CropOp<CPUDevice, T>);\n",
    "REGISTER_CPU(float);\n",
    "REGISTER_CPU(int32);\n",
    "\n",
    "// Register the GPU kernels.\n",
    "#ifdef GOOGLE_CUDA\n",
    "#define REGISTER_GPU(T) \\\n",
    "  extern template struct CropFunctor<GPUDevice, T>; \\\n",
    "  REGISTER_KERNEL_BUILDER( \\\n",
    "      Name(\"Crop\")      \\\n",
    "      .Device(DEVICE_GPU)   \\\n",
    "      .TypeConstraint<T>(\"T\"),  \\\n",
    "    CropOp<GPUDevice, T>);\n",
    "REGISTER_GPU(float);\n",
    "REGISTER_GPU(int32);\n",
    "#endif // GOOGLE_CUDA\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `crop_op.cu.cc`\n",
    "This is the CUDA kernel definition itself. \n",
    "\n",
    "```cpp\n",
    "#ifdef GOOGLE_CUDA\n",
    "#define EIGEN_USE_GPU\n",
    "\n",
    "#include \"crop_op.h\"\n",
    "#include \"tensorflow/core/util/cuda_kernel_helper.h\"\n",
    "\n",
    "using namespace tensorflow;\n",
    "\n",
    "using GPUDevice = Eigen::GpuDevice;\n",
    "\n",
    "// Define the CUDA kernel.\n",
    "// template <typename T>\n",
    "// __global__ void CropCudaKernel\n",
    "// ...\n",
    "```\n",
    "Our custom CUDA kernel implementation should come around here.\n",
    "```cpp\n",
    "// Define the GPU implementation that launches the CUDA kernel.\n",
    "template <typename T>\n",
    "void CropFunctor<GPUDevice, T>::operator()(\n",
    "    const GPUDevice& d,\n",
    "    const T* image_ptr,\n",
    "    const int* crop_centers_ptr,\n",
    "    int crop_size,\n",
    "    int image_size,\n",
    "    int channels,\n",
    "    int num_crops,\n",
    "    T* crops_ptr\n",
    "  ) {\n",
    "  // Launch the cuda kernel.\n",
    "  int block_count = num_crops;\n",
    "  int thread_per_block = 1024;\n",
    "  CropCudaKernel<T>\n",
    "      <<<block_count, thread_per_block, 0, d.stream()>>>(\n",
    "        image_ptr,\n",
    "        crop_centers_ptr,\n",
    "        image_size,\n",
    "        channels,\n",
    "        crop_size,\n",
    "        num_crops,\n",
    "        crops_ptr\n",
    "      );\n",
    "    cudaDeviceSynchronize();\n",
    "}\n",
    "\n",
    "// Explicitly instantiate functors for the types of OpKernels registered.\n",
    "template struct CropFunctor<GPUDevice, float>;\n",
    "template struct CropFunctor<GPUDevice, int32>;\n",
    "\n",
    "#endif // GOOGLE_CUDA\n",
    "```\n",
    "This is the function that will set the number of blocks and threads per block before calling the kernel. The syntax to call the kernel is slightly different from the syntax for a normal function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling\n",
    "You have to first compile the CUDA kernel using `nvcc` compiler, then compile the C++ wrappers with `g++` compiler. There are many subtleties that I do not master in this compilation chain and linking, but in short, here is a Makefile that worked for me (and runs both on CPU and GPU).\n",
    "\n",
    "```makefile\n",
    "#Get location of Tensorflow headers and library files\n",
    "TF_INC=$(shell python -c 'import tensorflow as tf; print(tf.sysconfig.get_include())')\n",
    "TF_LIB=$(shell python -c 'import tensorflow as tf; print(tf.sysconfig.get_lib())')\n",
    "\n",
    "CC        = gcc -O2 -pthread\n",
    "CXX       = g++\n",
    "GPUCC     = nvcc\n",
    "CFLAGS    = -std=c++11 -I$(TF_INC) -D_GLIBCXX_USE_CXX11_ABI=0\n",
    "GPUCFLAGS = -c\n",
    "LFLAGS    =  -shared -fPIC -ltensorflow_framework -I$(TF_INC) -I$(TF_INC)/external/nsync/public -L$(TF_LIB) -L/usr/local/cuda/lib64 -I/usr/local/cuda/include\n",
    "GPULFLAGS = -x cu -shared -Xcompiler -fPIC -ltensorflow_framework -I$(TF_INC) -I$(TF_INC)/external/nsync/public -L$(TF_LIB)\n",
    "DEBUG = -g -G\n",
    "GPUDEF    = -D GOOGLE_CUDA=1\n",
    "CGPUFLAGS = -lcudart\n",
    "\n",
    "\n",
    "SRC       = crop_op.cc\n",
    "GPUSRC    = crop_op_gpu.cu.cc\n",
    "PROD      = crop_op.so\n",
    "GPUPROD = crop_op_cu.so\n",
    "\n",
    "default: gpu\n",
    "\n",
    "cpu:\n",
    "\t$(CXX) $(CFLAGS) $(SRC) $(LFLAGS) -o $(PROD)\n",
    "\n",
    "gpu:\n",
    "\t$(GPUCC) $(CFLAGS) $(GPUCFLAGS) $(GPUSRC) $(GPULFLAGS) -o $(GPUPROD) $(GPUDEF) -I/usr/local/ --expt-relaxed-constexpr -D_MWAITXINTRIN_H_INCLUDED\n",
    "\t$(CXX) $(CFLAGS)  $(SRC) $(GPUPROD) $(LFLAGS) $(CGPUFLAGS) -o $(PROD) $(GPUDEF)\n",
    "\n",
    "clean:\n",
    "\trm -f $(PROD) $(GPUPROD)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing and using our new Tensorflow operation\n",
    "We can use the tensorflow `TestCase` class to test our new operation. Let us first define a CPU, Numpy implementation of the cropping operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def crop(patch_centers, N, data):\n",
    "    \"\"\"\n",
    "    Slice patches of size N centered at patch_centers in data.\n",
    "    Assumes data has shape (1, M, M, M, channels)\n",
    "    or (1, M, M, channels)\n",
    "    \"\"\"\n",
    "    coords0 = np.floor(patch_centers - N/2.0)  # bottom left corner\n",
    "    coords1 = np.floor(patch_centers + N/2.0)  # top right corner\n",
    "    dim = patch_centers.shape[1]\n",
    "    image_size = data.shape[1]\n",
    "    coords0 = np.clip(coords0, 0, image_size).astype(int)\n",
    "    coords1 = np.clip(coords1, 0, image_size).astype(int)\n",
    "    crops = np.zeros((coords0.shape[0],) + (N,) * dim + (data.shape[-1],))\n",
    "    crops_labels = np.zeros_like(crops)\n",
    "    for j in range(len(coords0)):\n",
    "        padding = []\n",
    "        for d in range(dim):\n",
    "            pad = np.maximum(N - (coords1[j, d] - coords0[j, d]), 0)\n",
    "            if coords0[j, d] == 0.0:\n",
    "                padding.append((pad, 0))\n",
    "            else:\n",
    "                padding.append((0, pad))\n",
    "        padding.append((0, 0))\n",
    "        if dim == 2:\n",
    "            crops[j] = np.pad(data[0,\n",
    "                                   coords0[j, 0]:coords1[j, 0],\n",
    "                                   coords0[j, 1]:coords1[j, 1],\n",
    "                                   :],\n",
    "                              padding, 'constant')\n",
    "        else:  # dim == 3\n",
    "            crops[j] = np.pad(data[0,\n",
    "                                   coords0[j, 0]:coords1[j, 0],\n",
    "                                   coords0[j, 1]:coords1[j, 1],\n",
    "                                   coords0[j, 2]:coords1[j, 2],\n",
    "                                   :],\n",
    "                              padding, 'constant')\n",
    "    return crops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define our test and compare the timing between Numpy and CUDA implementations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CropTest(tf.test.TestCase):\n",
    "    def testCrop(self):\n",
    "        crop_module = tf.load_op_library('./faster_particles/crop_op/crop_op.so')\n",
    "\n",
    "        np.random.seed(123)\n",
    "        tf.set_random_seed(123)\n",
    "        \n",
    "        N = 192\n",
    "        # The more steps here, the more accurate the timings will be\n",
    "        # Remember that TF first few calls to sess.run are always slower\n",
    "        MAX_STEPS = 200\n",
    "        CROP_SIZE = 64\n",
    "        \n",
    "        # Define dummy crop centers\n",
    "        image_np = (np.random.rand(N, N, N, 1) * N).astype(np.float32)\n",
    "        crop_centers_np = np.random.randint(50, high=100, size=(100, 3))\n",
    "        \n",
    "        # Define TF equivalents\n",
    "        image = tf.constant(image_np, dtype=tf.float32)\n",
    "        crop_centers = tf.constant(crop_centers_np, dtype=tf.int32)\n",
    "        \n",
    "        # >>> Call our CUDA kernel! <<<\n",
    "        crops = crop_module.crop(image, crop_centers, CROP_SIZE)\n",
    "        \n",
    "        with self.test_session():\n",
    "            duration = 0\n",
    "            for i in range(MAX_STEPS):\n",
    "                start = time.time()\n",
    "                tf_result = crops.eval()\n",
    "                end = time.time()\n",
    "                duration += end - start\n",
    "            print(\"TF duration = %f s\" % (duration / MAX_STEPS))\n",
    "            duration = 0\n",
    "            for i in range(MAX_STEPS):\n",
    "                start = time.time()\n",
    "                np_result, _ = crop_numpy(crop_centers_np, CROP_SIZE, image_np[np.newaxis, ...])\n",
    "                end = time.time()\n",
    "                duration += end - start\n",
    "            print(\"NP duration = %f s\" % (duration / MAX_STEPS))\n",
    "            self.assertAllClose(tf_result, np_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the test just execute the following line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.test.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The timing outcomes are in my case:\n",
    "```bash\n",
    "TF duration = 0.011914 s\n",
    "NP duration = 0.138170 s\n",
    "\n",
    "```\n",
    "So we get a speedup of 10x for this small toy example. It is not *that* spectacular, because the number of blocks is relatively low (100 * 64 = 6400 blocks). By tuning the number of blocks, threads per block etc, the speedup could probably be better. How much will you be able to achieve with your own use case? Let us know!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
