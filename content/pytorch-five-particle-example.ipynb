{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Classification Example\n",
    "\n",
    "In this notebook, we're going to use ResNet-18 implemented in pyTorch to classify the 5-particle example training data.\n",
    "\n",
    "This tutorial is meant to walk through some of the necessary steps to load images stored in LArCV files and train a network.  For more details on how to use pytorch, refer to the official pytorch tutorials.\n",
    "\n",
    "This notebook will try to be self-contained in terms of code. \n",
    "However, you can find the code separated into different files in the following repositories\n",
    "\n",
    "* LArCVDataset: concrete instance of pytorch Dataset class written for LArCV2 IO\n",
    "* pytorch-classification-example: many of the files and scripts found in this tutorial\n",
    "\n",
    "You will also need the training data. Go to the [open data page](http://deeplearnphysics.org/DataChallenge/) and download the either the 5k or 50k training/validation samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.12/04\n"
     ]
    }
   ],
   "source": [
    "# Import our modules\n",
    "\n",
    "# python\n",
    "import os,sys\n",
    "import shutil\n",
    "import time\n",
    "import traceback\n",
    "\n",
    "# numpy\n",
    "import numpy as np\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "# ROOT/LArCV\n",
    "import ROOT\n",
    "from larcv import larcv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the GPU to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.cuda.device at 0x7f1fc0135cd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device( 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Data IO\n",
    "\n",
    "## Location of data on your local machine\n",
    "\n",
    "Set the path to the data files in this block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_train_data=\"/home/taritree/working/dlphysics/testset/train_50k.root\"\n",
    "path_to_test_data=\"/home/taritree/working/dlphysics/testset/test_40k.root\"\n",
    "if not os.path.exists(path_to_train_data):\n",
    "    print \"Could not find the training data file.\"\n",
    "if not os.path.exists(path_to_test_data):\n",
    "    print \"Could not find the validation data file.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define LArCVDataset\n",
    "\n",
    "First, we define a class that will load our data. There are many ways to do this. We create a concrete instance of pytorch's `Dataset` class, which can be used in the `DataLoader` class (which we do not use)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from: https://github.com/deeplearnphysics/larcvdataset\n",
    "\n",
    "larcv.PSet # touch this to force libBase to load, which has CreatePSetFromFile\n",
    "from larcv.dataloader2 import larcv_threadio\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class LArCVDataset(Dataset):\n",
    "    \"\"\" LArCV data set interface for PyTorch\"\"\"\n",
    "\n",
    "    def __init__( self, cfg, fillername, verbosity=0, loadallinmem=False, randomize_inmem_data=True, max_inmem_events=-1 ):\n",
    "        self.verbosity = verbosity\n",
    "        self.batchsize = None\n",
    "        self.randomize_inmem_data = randomize_inmem_data\n",
    "        self.max_inmem_events = max_inmem_events\n",
    "        self.loadallinmem = loadallinmem\n",
    "        self.cfg = cfg  \n",
    "\n",
    "        # we setup the larcv threadfiller class, which handles io from larcv files\n",
    "        # this follows steps from larcv tutorials\n",
    "        \n",
    "        # setup cfg dictionary needed for larcv_threadio      \n",
    "        self.filler_cfg = {}\n",
    "        self.filler_cfg[\"filler_name\"] = fillername\n",
    "        self.filler_cfg[\"verbosity\"]   = self.verbosity\n",
    "        self.filler_cfg[\"filler_cfg\"]  = self.cfg\n",
    "        if not os.path.exists(self.cfg):\n",
    "            raise ValueError(\"Could not find filler configuration file: %s\"%(self.cfg))\n",
    "\n",
    "        # we read the first line of the config file, which should have name of config parameter set\n",
    "        linepset = open(self.cfg,'r').readlines()\n",
    "        self.cfgname = linepset[0].split(\":\")[0].strip()\n",
    "        \n",
    "        # we load the pset ourselves, as we want access to values in 'ProcessName' list\n",
    "        # will use these as the names of the data products loaded. store in self.datalist\n",
    "        self.pset = larcv.CreatePSetFromFile(self.cfg,self.cfgname).get(\"larcv::PSet\")(self.cfgname)\n",
    "        datastr_v = self.pset.get(\"std::vector<std::string>\")(\"ProcessName\")\n",
    "        self.datalist = []\n",
    "        for i in range(0,datastr_v.size()):\n",
    "            self.datalist.append(datastr_v[i])\n",
    "        \n",
    "        # finally, configure io\n",
    "        self.io = larcv_threadio()        \n",
    "        self.io.configure(self.filler_cfg)\n",
    "        \n",
    "        if self.loadallinmem:\n",
    "            self._loadinmem()\n",
    "\n",
    "    def __len__(self):\n",
    "        if not self.loadallinmem:\n",
    "            return int(self.io.fetch_n_entries())\n",
    "        else:\n",
    "            return int(self.alldata[self.datalist[0]].shape[0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if not self.loadallinmem:\n",
    "            self.io.next()\n",
    "            out = {}\n",
    "            for name in self.datalist:\n",
    "                out[name] = self.io.fetch_data(name).data()\n",
    "        else:\n",
    "            indices = np.random.randint(len(self),size=self.batchsize)\n",
    "            out = {}\n",
    "            for name in self.datalist:\n",
    "                out[name] = np.zeros( (self.batchsize,self.alldata[name].shape[1]), self.alldata[name].dtype )\n",
    "                for n,idx in enumerate(indices):\n",
    "                    out[name][n,:] = self.alldata[name][idx,:]\n",
    "        return out\n",
    "        \n",
    "    def __str__(self):\n",
    "        return dumpcfg()\n",
    "    \n",
    "    def _loadinmem(self):\n",
    "        \"\"\"load data into memory\"\"\"\n",
    "        nevents = int(self.io.fetch_n_entries())\n",
    "        if self.max_inmem_events>0 and nevents>self.max_inmem_events:\n",
    "            nevents = self.max_inmem_events\n",
    "\n",
    "        print \"Attempting to load all \",nevents,\" into memory. good luck\"\n",
    "        start = time.time()\n",
    "\n",
    "        # start threadio\n",
    "        self.start(1)\n",
    "\n",
    "        # get one data element to get shape\n",
    "        self.io.next()\n",
    "        firstout = {}\n",
    "        for name in self.datalist:\n",
    "            firstout[name] = self.io.fetch_data(name).data()\n",
    "            self.alldata = {}\n",
    "        for name in self.datalist:\n",
    "            self.alldata[name] = np.zeros( (nevents,firstout[name].shape[1]), firstout[name].dtype )\n",
    "            self.alldata[name][0] = firstout[name][0,:]\n",
    "        for i in range(1,nevents):\n",
    "            self.io.next()\n",
    "            if i%100==0:\n",
    "                print \"loading event %d of %d\"%(i,nevents)\n",
    "            for name in self.datalist:\n",
    "                out = self.io.fetch_data(name).data()\n",
    "                self.alldata[name][i,:] = out[0,:]\n",
    "\n",
    "        print \"elapsed time to bring data into memory: \",time.time()-start,\"sec\"\n",
    "        self.stop()\n",
    "\n",
    "    def start(self,batchsize):\n",
    "        \"\"\"exposes larcv_threadio::start which is used to start the thread managers\"\"\"\n",
    "        self.batchsize = batchsize\n",
    "        self.io.start_manager(self.batchsize)\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\" stops the thread managers\"\"\"\n",
    "        self.io.stop_manager()\n",
    "\n",
    "    def dumpcfg(self):\n",
    "        \"\"\"dump the configuration file to a string\"\"\"\n",
    "        print open(self.cfg).read()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write configuration files for the LArCV ThreadFiller class\n",
    "\n",
    "We define the configurations in this block, then write to file. We will load the files later when we create LArCVDataset instances for both the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cfg=\"\"\"ThreadProcessor: {\n",
    "  Verbosity:3\n",
    "  NumThreads: 3\n",
    "  NumBatchStorage: 3\n",
    "  RandomAccess: true\n",
    "  InputFiles: [\"%s\"]  \n",
    "  ProcessName: [\"image\",\"label\"]\n",
    "  ProcessType: [\"BatchFillerImage2D\",\"BatchFillerPIDLabel\"]\n",
    "  ProcessList: {\n",
    "    image: {\n",
    "      Verbosity:3\n",
    "      ImageProducer: \"data\"\n",
    "      Channels: [2]\n",
    "      EnableMirror: true\n",
    "    }\n",
    "    label: {\n",
    "      Verbosity:3\n",
    "      ParticleProducer: \"mctruth\"\n",
    "      PdgClassList: [2212,11,211,13,22]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\"%(path_to_train_data)\n",
    "\n",
    "test_cfg=\"\"\"ThreadProcessorTest: {\n",
    "  Verbosity:3\n",
    "  NumThreads: 2\n",
    "  NumBatchStorage: 2\n",
    "  RandomAccess: true\n",
    "  InputFiles: [\"%s\"]\n",
    "  ProcessName: [\"imagetest\",\"labeltest\"]\n",
    "  ProcessType: [\"BatchFillerImage2D\",\"BatchFillerPIDLabel\"]\n",
    "  ProcessList: {\n",
    "    imagetest: {\n",
    "      Verbosity:3\n",
    "      ImageProducer: \"data\"\n",
    "      Channels: [2]\n",
    "      EnableMirror: false\n",
    "    }\n",
    "    labeltest: {\n",
    "      Verbosity:3\n",
    "      ParticleProducer: \"mctruth\"\n",
    "      PdgClassList: [2212,11,211,13,22]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\"%(path_to_test_data)\n",
    "\n",
    "train_cfg_out = open(\"train_dataloader.cfg\",'w')\n",
    "print >> train_cfg_out,train_cfg\n",
    "train_cfg_out.close()\n",
    "\n",
    "test_cfg_out  = open(\"valid_dataloader.cfg\",'w')\n",
    "print >> test_cfg_out,test_cfg\n",
    "test_cfg_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Network\n",
    "\n",
    "## Define network\n",
    "\n",
    "We use ResNet-18 as implemented in the torchvision module.  We reproduce it here and make a slight modification: we change the number of input channels from 3 to 1.  The original resnet expects an RGB image.  For our example, we only use the image from one plane from our hypothetical LAr TPC detector.\n",
    "\n",
    "Original can be found [here](https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "# define convolution without bias that we will use throughout the network\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "# implements one ResNet unit\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "# define the network. It provides options for \n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000, input_channels=3):\n",
    "        \"\"\"\n",
    "        inputs\n",
    "        ------\n",
    "        block: type of resnet unit\n",
    "        layers: list of 4 ints. defines number of basic block units in each set of resnet units\n",
    "        num_classes: output classes\n",
    "        input_channels: number of channels in input images\n",
    "        \"\"\"\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        \n",
    "        # had to change stride of avgpool from original from 1 to 2\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=2)\n",
    "\n",
    "        # I've added dropout to the network\n",
    "        self.dropout = nn.Dropout2d(p=0.5,inplace=True)\n",
    "\n",
    "        #print \"block.expansion=\",block.expansion                                                                                                                                                           \n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = self.dropout(x)\n",
    "        #print \"avepool: \",x.data.shape                                                                                                                                                                     \n",
    "        x = x.view(x.size(0), -1)\n",
    "        #print \"view: \",x.data.shape                                                                                                                                                                        \n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "    \n",
    "# define a helper function for ResNet-18\n",
    "def resnet18(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.                                                                                                                                                                        \n",
    "                                                                                                                                                                                                            \n",
    "    Args:                                                                                                                                                                                                   \n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet                                                                                                                                 \n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create instance of network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d (1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1))\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d (64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d (64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d (64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d (64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d (64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d (64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d (128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d (128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d (256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d (256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=2, padding=0, ceil_mode=False, count_include_pad=True)\n",
       "  (dropout): Dropout2d(p=0.5, inplace)\n",
       "  (fc): Linear(in_features=512, out_features=5)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = resnet18(pretrained=False,num_classes=5, input_channels=1)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define optimizer and set training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1.0e-3\n",
    "momentum = 0.9\n",
    "weight_decay = 1.0e-3\n",
    "batchsize = 50\n",
    "batchsize_valid = 500\n",
    "start_epoch = 0\n",
    "epochs      = 1500\n",
    "nbatches_per_epoch = 10000/batchsize\n",
    "nbatches_per_valid = 1000/batchsize_valid\n",
    "\n",
    "# We use SGD\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr, momentum=momentum, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define training and validation steps\n",
    "\n",
    "We define functions and classes to help us perform training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define an object that will help us track averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, nbatches, epoch, print_freq):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    format_time = AverageMeter()\n",
    "    train_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to train mode                                                                                                                                                                                  \n",
    "    model.train()\n",
    "\n",
    "    for i in range(0,nbatches):\n",
    "        #print \"epoch \",epoch,\" batch \",i,\" of \",nbatches                                                                                                                                                   \n",
    "        batchstart = time.time()\n",
    "\n",
    "        end = time.time()\n",
    "        data = train_loader[i]\n",
    "        # measure data loading time                                                                                                                                                                         \n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        end = time.time()\n",
    "        img = data[\"image\"]\n",
    "        lbl = data[\"label\"]\n",
    "        img_np = np.zeros( (img.shape[0], 1, 256, 256), dtype=np.float32 )\n",
    "        lbl_np = np.zeros( (lbl.shape[0] ), dtype=np.int )\n",
    "        # batch loop                                                                                                                                                                                        \n",
    "        for j in range(img.shape[0]):\n",
    "            imgtmp = img[j].reshape( (256,256) )\n",
    "            img_np[j,0,:,:] = padandcropandflip(imgtmp) # data augmentation                                                                                                                                 \n",
    "            lbl_np[j] = np.argmax(lbl[j])\n",
    "        input  = torch.from_numpy(img_np).cuda()\n",
    "        target = torch.from_numpy(lbl_np).cuda()\n",
    "\n",
    "        # measure data formatting time                                                                                                                                                                      \n",
    "        format_time.update(time.time() - end)\n",
    "\n",
    "\n",
    "        input_var = torch.autograd.Variable(input)\n",
    "        target_var = torch.autograd.Variable(target)\n",
    "\n",
    "        # compute output                                                                                                                                                                                    \n",
    "        end = time.time()\n",
    "        output = model(input_var)\n",
    "        loss = criterion(output, target_var)\n",
    "\n",
    "        # measure accuracy and record loss                                                                                                                                                                  \n",
    "        prec1 = accuracy(output.data, target, topk=(1,))\n",
    "        losses.update(loss.data[0], input.size(0))\n",
    "        top1.update(prec1[0], input.size(0))\n",
    "        \n",
    "        # compute gradient and do SGD step                                                                                                                                                                  \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_time.update(time.time()-end)\n",
    "\n",
    "        # measure elapsed time                                                                                                                                                                              \n",
    "        batch_time.update(time.time() - batchstart)\n",
    "        \n",
    "        if i % print_freq == 0:\n",
    "            status = (epoch,i,nbatches,\n",
    "                      batch_time.val,batch_time.avg,\n",
    "                      data_time.val,data_time.avg,\n",
    "                      format_time.val,format_time.avg,\n",
    "                      train_time.val,train_time.avg,\n",
    "                      losses.val,losses.avg,\n",
    "                      top1.val,top1.avg)\n",
    "            print \"Epoch: [%d][%d/%d]\\tTime %.3f (%.3f)\\tData %.3f (%.3f)\\tFormat %.3f (%.3f)\\tTrain %.3f (%.3f)\\tLoss %.3f (%.3f)\\tPrec@1 %.3f (%.3f)\"%status\n",
    "            \n",
    "    return losses.avg,top1.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation step\n",
    "\n",
    "Here we process the test data and accumilate the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion, nbatches, print_freq):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode                                                                                                                                                                               \n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    for i in range(0,nbatches):\n",
    "        data = val_loader[i]\n",
    "        img = data[\"imagetest\"]\n",
    "        lbl = data[\"labeltest\"]\n",
    "        img_np = np.zeros( (img.shape[0], 1, 256, 256), dtype=np.float32 )\n",
    "        lbl_np = np.zeros( (lbl.shape[0] ), dtype=np.int )\n",
    "        for j in range(img.shape[0]):\n",
    "            img_np[j,0,:,:] = img[j].reshape( (256,256) )\n",
    "            lbl_np[j] = np.argmax(lbl[j])\n",
    "        input  = torch.from_numpy(img_np).cuda()\n",
    "        target = torch.from_numpy(lbl_np).cuda()\n",
    "\n",
    "        input_var = torch.autograd.Variable(input, volatile=True)\n",
    "        target_var = torch.autograd.Variable(target, volatile=True)\n",
    "\n",
    "        # compute output                                                                                                                                                                                    \n",
    "        output = model(input_var)\n",
    "        loss = criterion(output, target_var)\n",
    "\n",
    "        # measure accuracy and record loss                                                                                                                                                                  \n",
    "        prec1 = accuracy(output.data, target, topk=(1,))\n",
    "        losses.update(loss.data[0], input.size(0))\n",
    "        top1.update(prec1[0], input.size(0))\n",
    "\n",
    "        # measure elapsed time                                                                                                                                                                              \n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if i % print_freq == 0:\n",
    "            status = (i,nbatches,batch_time.val,batch_time.avg,losses.val,losses.avg,top1.val,top1.avg)\n",
    "            print \"Test: [%d/%d]\\tTime %.3f (%.3f)\\tLoss %.3f (%.3f)\\tPrec@1 %.3f (%.3f)\"%status\n",
    " \n",
    "    print \"Test:Result* Prec@1 %.3f\\tLoss %.3f\"%(top1.avg,losses.avg)\n",
    "    \n",
    "    return float(top1.avg),float(losses.avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch, lr):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    #lr = lr * (0.5 ** (epoch // 300))                                                                                                                                                                      \n",
    "    lr = lr\n",
    "    #lr = lr*0.992                                                                                                                                                                                          \n",
    "    #print \"adjust learning rate to \",lr                                                                                                                                                                    \n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "def dump_lr_schedule( startlr, numepochs ):\n",
    "    for epoch in range(0,numepochs):\n",
    "        lr = startlr*(0.5**(epoch//300))\n",
    "        if epoch%10==0:\n",
    "            print \"Epoch [%d] lr=%.3e\"%(epoch,lr)\n",
    "    print \"Epoch [%d] lr=%.3e\"%(epoch,lr)\n",
    "    return\n",
    "\n",
    "def padandcropandflip(npimg2d):\n",
    "    imgpad  = np.zeros( (264,264), dtype=np.float32 )\n",
    "    imgpad[4:256+4,4:256+4] = npimg2d[:,:]\n",
    "    if np.random.rand()>0.5:\n",
    "        imgpad = np.flip( imgpad, 0 )\n",
    "    if np.random.rand()>0.5:\n",
    "        imgpad = np.flip( imgpad, 1 )\n",
    "    randx = np.random.randint(0,8)\n",
    "    randy = np.random.randint(0,8)\n",
    "    return imgpad[randx:randx+256,randy:randy+256]\n",
    "\n",
    "def save_checkpoint(state, is_best, p, filename='checkpoint.pth.tar'):\n",
    "    if p>0:\n",
    "        filename = \"checkpoint.%dth.tar\"%(p)\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the datasets and start data loading threads\n",
    "\n",
    "\n",
    "### Training data\n",
    "\n",
    "For the training data, we ask that all the data is loaded into memory. Since we need to get many, many batches to train the network, reducing the time to get a batch of images will pay off in the long run.\n",
    "\n",
    "However, we first pay an upgront cost: this step takes a LONG time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load all  100  into memory. good luck\n",
      "elapsed time to bring data into memory:  5.44157385826 sec\n",
      "ThreadProcessor : {\n",
      "  InputFiles : [\"/home/taritree/working/dlphysics/testset/train_50k.root\"]\n",
      "  NumBatchStorage : 3\n",
      "  NumThreads : 3\n",
      "  ProcessName : [\"image\",\"label\"]\n",
      "  ProcessType : [\"BatchFillerImage2D\",\"BatchFillerPIDLabel\"]\n",
      "  RandomAccess : true\n",
      "  Verbosity : 3\n",
      "  ProcessList : {\n",
      "    image : {\n",
      "      Channels : [2]\n",
      "      EnableMirror : true\n",
      "      ImageProducer : \"data\"\n",
      "      Verbosity : 3\n",
      "    }\n",
      "\n",
      "    label : {\n",
      "      ParticleProducer : \"mctruth\"\n",
      "      PdgClassList : [2212,11,211,13,22]\n",
      "      Verbosity : 3\n",
      "    }\n",
      "\n",
      "  }\n",
      "\n",
      "}\n",
      "\n",
      "\u001b[93m setting verbosity \u001b[00m3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in <TProtoClass::FindDataMember>: data member with index 0 is not found in class thread\n",
      "Error in <CreateRealData>: Cannot find data member # 0 of class thread for parent larcv::ThreadProcessor!\n"
     ]
    }
   ],
   "source": [
    "capevents = 100 # for debugging, to keep the time this step takes to a minimum\n",
    "iotrain = LArCVDataset(\"train_dataloader.cfg\", \"ThreadProcessor\", loadallinmem=True, max_inmem_events=capevents)\n",
    "iotrain.start(batchsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation data\n",
    "\n",
    "For the validation data, we do not load data into memory all at once. We will use the validation only periodically, in between many training steps. During those training steps, the thread filler will load data into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m setting verbosity \u001b[00m3\n"
     ]
    }
   ],
   "source": [
    "iovalid = LArCVDataset(\"valid_dataloader.cfg\", \"ThreadProcessorTest\")\n",
    "iovalid.start(batchsize_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0\n",
      "Epoch: [0][0/200]\tTime 0.096 (0.096)\tData 0.005 (0.005)\tFormat 0.013 (0.013)\tTrain 0.077 (0.077)\tLoss 0.002 (0.002)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [0][50/200]\tTime 0.212 (0.206)\tData 0.003 (0.004)\tFormat 0.134 (0.126)\tTrain 0.075 (0.076)\tLoss 0.004 (0.013)\tPrec@1 100.000 (99.765)\n",
      "Epoch: [0][100/200]\tTime 0.212 (0.208)\tData 0.003 (0.004)\tFormat 0.133 (0.128)\tTrain 0.075 (0.076)\tLoss 0.008 (0.012)\tPrec@1 100.000 (99.762)\n",
      "Epoch: [0][150/200]\tTime 0.212 (0.209)\tData 0.004 (0.004)\tFormat 0.129 (0.129)\tTrain 0.079 (0.076)\tLoss 0.005 (0.012)\tPrec@1 100.000 (99.775)\n",
      "Test: [0/2]\tTime 0.741 (0.741)\tLoss 2.303 (2.303)\tPrec@1 50.200 (50.200)\n",
      "Test: [1/2]\tTime 0.736 (0.738)\tLoss 2.461 (2.382)\tPrec@1 51.200 (50.700)\n",
      "Test:Result* Prec@1 50.700\tLoss 2.382\n",
      "Epoch: [1][0/200]\tTime 0.094 (0.094)\tData 0.004 (0.004)\tFormat 0.011 (0.011)\tTrain 0.079 (0.079)\tLoss 0.005 (0.005)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [1][50/200]\tTime 0.220 (0.215)\tData 0.004 (0.004)\tFormat 0.139 (0.132)\tTrain 0.077 (0.079)\tLoss 0.005 (0.007)\tPrec@1 100.000 (100.000)\n",
      "Epoch: [1][100/200]\tTime 0.220 (0.216)\tData 0.004 (0.004)\tFormat 0.139 (0.134)\tTrain 0.077 (0.078)\tLoss 0.028 (0.009)\tPrec@1 98.000 (99.861)\n",
      "Epoch: [1][150/200]\tTime 0.215 (0.216)\tData 0.003 (0.004)\tFormat 0.135 (0.134)\tTrain 0.076 (0.078)\tLoss 0.002 (0.009)\tPrec@1 100.000 (99.868)\n",
      "Test: [0/2]\tTime 0.720 (0.720)\tLoss 2.839 (2.839)\tPrec@1 51.000 (51.000)\n",
      "Test: [1/2]\tTime 0.722 (0.721)\tLoss 2.669 (2.754)\tPrec@1 49.000 (50.000)\n",
      "Test:Result* Prec@1 50.000\tLoss 2.754\n",
      "Epoch: [2][0/200]\tTime 0.091 (0.091)\tData 0.004 (0.004)\tFormat 0.009 (0.009)\tTrain 0.079 (0.079)\tLoss 0.009 (0.009)\tPrec@1 100.000 (100.000)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-293d595c93b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# train for one epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mtrain_ave_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ave_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miotrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbatches_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Error in training routine!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-e77ed9a550ef>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, nbatches, epoch, print_freq)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mimg_np\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpadandcropandflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgtmp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# data augmentation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mlbl_np\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlbl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0minput\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_np\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlbl_np\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/taritree/.local/lib/python2.7/site-packages/torch/_utils.pyc\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_prec1 = 0.0\n",
    "\n",
    "# we store output from the training loop\n",
    "traininglog = open(\"log_training.txt\",'w')\n",
    "\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    if epoch%10==0:\n",
    "        print \"Epoch \",epoch\n",
    "    adjust_learning_rate(optimizer, epoch, lr)\n",
    "    epochout = \"Epoch [%d]: \"%(epoch)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        epochout += \"lr=%.3e\"%(param_group['lr'])\n",
    "    traininglog.write(epochout+'\\n')\n",
    "\n",
    "    # train for one epoch                                                                                                                                                                               \n",
    "    try:\n",
    "        train_ave_loss, train_ave_acc = train(iotrain, model, criterion, optimizer, nbatches_per_epoch, epoch, 50)\n",
    "    except Exception,e:\n",
    "        print \"Error in training routine!\"\n",
    "        print e.message\n",
    "        print e.__class__.__name__\n",
    "        traceback.print_exc(e)\n",
    "        break\n",
    "    traininglog.write( \"Epoch [%d] train aveloss=%.3f aveacc=%.3f\\n\"%(epoch,train_ave_loss,train_ave_acc) )\n",
    "\n",
    "    # evaluate on validation set                                                                                                                                                                        \n",
    "    try:\n",
    "        prec1,valid_loss = validate(iovalid, model, criterion, nbatches_per_valid, 1)\n",
    "    except Exception,e:\n",
    "        print \"Error in validation routine!\"\n",
    "        print e.message\n",
    "        print e.__class__.__name__\n",
    "        traceback.print_exc(e)\n",
    "        break\n",
    "    traininglog.write( \"Test[%d]:Result* Prec@1 %.3f\\tLoss %.3f\\n\"%(epoch,prec1,valid_loss) )\n",
    "        \n",
    "    # remember best prec@1 and save checkpoint                                                                                                                                                          \n",
    "    is_best = prec1 > best_prec1\n",
    "    best_prec1 = max(prec1, best_prec1)\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_prec1': best_prec1,\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "    }, is_best, -1)\n",
    "    if epoch==5*50:\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_prec1': best_prec1,\n",
    "            'optimizer' : optimizer.state_dict(),\n",
    "        }, False, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,re\n",
    "\n",
    "\n",
    "def make_training_plot( logfile, outputpath ):\n",
    "\n",
    "    loglines = open(logfile,'r').readlines()\n",
    "\n",
    "    # store tuples (epoch,loss,acc)                                                                                                                                                                         \n",
    "    test_pts  = []\n",
    "    train_pts = []\n",
    "    lr_pts    = []\n",
    "    lr_max = 0\n",
    "    lr_min = 1.0e6\n",
    "\n",
    "    epoch_scale = 0.2\n",
    "\n",
    "    current_epoch = 0\n",
    "    for l in loglines:\n",
    "        l = l.strip()\n",
    "        data = l.split()\n",
    "        if \"train aveloss\" in l:\n",
    "            pt = ( int(filter(str.isdigit,data[1])), float(re.findall(\"\\d+\\.\\d+\",data[3])[0]), float(re.findall(\"\\d+\\.\\d+\",data[4])[0]) )\n",
    "            current_epoch = pt[0]\n",
    "            train_pts.append(pt)\n",
    "        if \"Test:Result*\" in l:\n",
    "            pt = ( current_epoch, float(data[4]), float(data[2]) )\n",
    "            test_pts.append(pt)\n",
    "        if \"lr=\" in l:\n",
    "            pt = ( int(filter(str.isdigit,data[1])), float( data[-1].split(\"=\")[-1] ) )\n",
    "            if pt[1]>lr_max:\n",
    "                lr_max = pt[1]\n",
    "            if pt[1]<lr_min:\n",
    "                lr_min = pt[1]\n",
    "            lr_pts.append( pt )\n",
    "\n",
    "\n",
    "    sys.argv.append(\"-b\")\n",
    "    import ROOT as rt\n",
    "    rt.gStyle.SetOptStat(0)\n",
    "\n",
    "    graphs = {}\n",
    "    graphs[\"trainacc\"]  = rt.TGraph( len(train_pts) )\n",
    "    graphs[\"trainloss\"] = rt.TGraph( len(train_pts) )\n",
    "    graphs[\"testacc\"]   = rt.TGraph( len(test_pts) )\n",
    "    graphs[\"testloss\"]  = rt.TGraph( len(test_pts) )\n",
    "    graphs[\"lr\"]        = rt.TGraph( len(lr_pts) )\n",
    "\n",
    "    accmax = 0\n",
    "    accmin = 1.0e6\n",
    "    lossmax = 0\n",
    "    lossmin = 1.0e6\n",
    "    for ipt,pt in enumerate(train_pts):\n",
    "        graphs[\"trainacc\"].SetPoint( ipt, pt[0]*epoch_scale, pt[2] )\n",
    "        graphs[\"trainloss\"].SetPoint( ipt, pt[0]*epoch_scale, pt[1] )\n",
    "        if accmax<pt[2]:\n",
    "            accmax = pt[2]\n",
    "        if accmin>pt[2]:\n",
    "            accmin = pt[2]\n",
    "        if lossmax<pt[1]:\n",
    "            lossmax = pt[1]\n",
    "        if lossmin>pt[1]:\n",
    "            lossmin = pt[1]\n",
    "\n",
    "    for ipt,pt in enumerate(test_pts):\n",
    "        graphs[\"testacc\"].SetPoint( ipt, pt[0]*epoch_scale, pt[2] )\n",
    "        graphs[\"testloss\"].SetPoint( ipt, pt[0]*epoch_scale, pt[1] )\n",
    "        if accmax<pt[2]:\n",
    "            accmax = pt[2]\n",
    "        if accmin>pt[2]:\n",
    "            accmin = pt[2]\n",
    "        if lossmax<pt[1]:\n",
    "            lossmax = pt[1]\n",
    "        if lossmin>pt[1]:\n",
    "            lossmin = pt[1]\n",
    "\n",
    "\n",
    "    c = rt.TCanvas(\"c\",\"\",1400,600)\n",
    "    c.Divide(2,1)\n",
    "\n",
    "    # hitogram to set scales                                                                                                                                                                                \n",
    "    hloss = rt.TH1D(\"hloss\",\";epoch;loss\",100, 0,train_pts[-1][0]*epoch_scale*1.1)\n",
    "    hloss.SetMinimum( 0.5*lossmin )\n",
    "    hloss.SetMaximum( 5.0*lossmax )\n",
    "\n",
    "    hacc = rt.TH1D(\"hacc\",\";epoch;accuracy (percent)\",100, 0,train_pts[-1][0]*epoch_scale*1.1)\n",
    "    hacc.SetMinimum( 0.0 )\n",
    "    hacc.SetMaximum( 100.0 )\n",
    "    \n",
    "        # Loss                                                                                                                                                                                                  \n",
    "    c.cd(1).SetLogy(1)\n",
    "    c.cd(1).SetGridx(1)\n",
    "    c.cd(1).SetGridy(1)\n",
    "    hloss.Draw()\n",
    "    graphs[\"trainloss\"].SetLineColor(rt.kBlack)\n",
    "    graphs[\"testloss\"].SetLineColor(rt.kBlue)\n",
    "    graphs[\"lr\"].SetLineColor(rt.kRed)\n",
    "    graphs[\"trainloss\"].Draw(\"LP\")\n",
    "    graphs[\"testloss\"].Draw(\"LP\")\n",
    "\n",
    "    # superimpose lr graph                                                                                                                                                                                  \n",
    "    rightmax = 1.1*lr_max\n",
    "    rightmin = 0.9*lr_min\n",
    "    scale    = rt.gPad.GetUymax()/rightmax\n",
    "    for ipt,pt in enumerate(lr_pts):\n",
    "        graphs[\"lr\"].SetPoint( ipt, pt[0]*epoch_scale, pt[1]*scale )\n",
    "    graphs[\"lr\"].Draw(\"LPsame\")\n",
    "    lraxis = rt.TGaxis( rt.gPad.GetUxmax(), rt.gPad.GetUymin(), rt.gPad.GetUxmax(), rt.gPad.GetUymax(), rightmin, rightmax, 510, \"+LG\" )\n",
    "    lraxis.SetLineColor(rt.kRed)\n",
    "    lraxis.SetLabelColor(rt.kRed)\n",
    "    lraxis.Draw()\n",
    "\n",
    "    # Accuracy                                                                                                                                                                                              \n",
    "    c.cd(2).SetLogy(0)\n",
    "    c.cd(2).SetGridx(1)\n",
    "    c.cd(2).SetGridy(1)\n",
    "    hacc.Draw()\n",
    "    graphs[\"trainacc\"].SetLineColor(rt.kBlack)\n",
    "    graphs[\"testacc\"].SetLineColor(rt.kBlue)\n",
    "    graphs[\"trainacc\"].Draw(\"LP\")\n",
    "    graphs[\"testacc\"].Draw(\"LP\")\n",
    "\n",
    "    c.Update()\n",
    "    c.Draw()\n",
    "\n",
    "    c.SaveAs(outputpath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a plot\n",
    "\n",
    "make_training_plot( \"log_training.txt\", \"training.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# once the training is over. stop the fillers\n",
    "iotrain.stop()\n",
    "iovalid.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
