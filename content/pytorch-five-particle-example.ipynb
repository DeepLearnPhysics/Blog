{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Classification Example\n",
    "\n",
    "In this notebook, we're going to use ResNet-18 implemented in pyTorch to classify the 5-particle example training data.\n",
    "\n",
    "This tutorial is meant to walk through some of the necessary steps to load images stored in LArCV files and train a network.  For more details on how to use pytorch, refer to the official pytorch tutorials.\n",
    "\n",
    "This notebook will try to be self-contained in terms of code. \n",
    "However, you can find the code separated into different files in the following repositories\n",
    "\n",
    "* LArCVDataset: concrete instance of pytorch Dataset class written for LArCV2 IO\n",
    "* pytorch-classification-example: many of the files and scripts found in this tutorial\n",
    "\n",
    "You will also need the training data. Go to the [open data page](http://deeplearnphysics.org/DataChallenge/) and download the either the 5k or 50k training/validation samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.12/04\n"
     ]
    }
   ],
   "source": [
    "# Import our modules\n",
    "\n",
    "# python\n",
    "import os,sys\n",
    "import shutil\n",
    "import time\n",
    "import traceback\n",
    "\n",
    "# numpy\n",
    "import numpy as np\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "# ROOT/LArCV\n",
    "import ROOT\n",
    "from larcv import larcv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Data IO\n",
    "\n",
    "## Location of data on your local machine\n",
    "\n",
    "Set the path to the data files in this block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_train_data=\"/home/taritree/working/dlphysics/testset/train_50k.root\"\n",
    "path_to_test_data=\"/home/taritree/working/dlphysics/testset/test_40k.root\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define LArCVDataset\n",
    "\n",
    "First, we define a class that will load our data. There is many ways to do this. We create a concrete instance of pytorch's `Dataset` class, which can be used in the `DataLoader` class (which we do not use)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from: https://github.com/deeplearnphysics/larcvdataset\n",
    "\n",
    "larcv.PSet # touch this to force libBase to load, which has CreatePSetFromFile\n",
    "from larcv.dataloader2 import larcv_threadio\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class LArCVDataset(Dataset):\n",
    "    \"\"\" LArCV data set interface for PyTorch\"\"\"\n",
    "\n",
    "    def __init__( self, cfg, verbosity=0 ):\n",
    "        self.verbosity = verbosity\n",
    "        self.batchsize = None\n",
    "\n",
    "        # we setup the larcv threadfiller class, which handles io from larcv files\n",
    "        # this follows steps from larcv tutorials\n",
    "        \n",
    "        # setup cfg dictionary needed for larcv_threadio\n",
    "        self.cfg = cfg        \n",
    "        self.filler_cfg = {}\n",
    "        self.filler_cfg[\"filler_name\"] = \"ThreadProcessor\"\n",
    "        self.filler_cfg[\"verbosity\"]   = self.verbosity\n",
    "        self.filler_cfg[\"filler_cfg\"]  = self.cfg\n",
    "        if not os.path.exists(self.cfg):\n",
    "            raise ValueError(\"Could not find filler configuration file: %s\"%(self.cfg))\n",
    "\n",
    "        # we read the first line of the config file, which should have name of config parameter set\n",
    "        linepset = open(self.cfg,'r').readlines()\n",
    "        self.cfgname = linepset[0].split(\":\")[0].strip()\n",
    "        \n",
    "        # we load the pset ourselves, as we want access to values in 'ProcessName' list\n",
    "        # will use these as the names of the data products loaded. store in self.datalist\n",
    "        self.pset = larcv.CreatePSetFromFile(self.cfg,self.cfgname).get(\"larcv::PSet\")(self.cfgname)\n",
    "        datastr_v = self.pset.get(\"std::vector<std::string>\")(\"ProcessName\")\n",
    "        self.datalist = []\n",
    "        for i in range(0,datastr_v.size()):\n",
    "            self.datalist.append(datastr_v[i])\n",
    "        \n",
    "        # finally, configure io\n",
    "        self.io = larcv_threadio()        \n",
    "        self.io.configure(self.filler_cfg)\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(self.io.fetch_n_entries())\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        self.io.next()\n",
    "        out = {}\n",
    "        for name in self.datalist:\n",
    "            out[name] = self.io.fetch_data(name).data()\n",
    "        return out\n",
    "        \n",
    "    def __str__(self):\n",
    "        return dumpcfg()\n",
    "\n",
    "    def start(self,batchsize):\n",
    "        \"\"\"exposes larcv_threadio::start which is used to start the thread managers\"\"\"\n",
    "        self.batchsize = batchsize\n",
    "        self.io.start_manager(self.batchsize)\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\" stops the thread managers\"\"\"\n",
    "        self.io.stop_manager()\n",
    "\n",
    "    def dumpcfg(self):\n",
    "        \"\"\"dump the configuration file to a string\"\"\"\n",
    "        print open(self.cfg).read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write configuration files for the LArCV ThreadFiller class\n",
    "\n",
    "We define the configurations in this block, then write to file. We will load the files later when we create LArCVDataset instances for both the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cfg=\"\"\"ThreadProcessor: {\n",
    "  Verbosity:3\n",
    "  NumThreads: 3\n",
    "  NumBatchStorage: 3\n",
    "  RandomAccess: true\n",
    "  InputFiles: [\"%s\"]  \n",
    "  ProcessName: [\"image\",\"label\"]\n",
    "  ProcessType: [\"BatchFillerImage2D\",\"BatchFillerPIDLabel\"]\n",
    "  ProcessList: {\n",
    "    image: {\n",
    "      Verbosity:3\n",
    "      ImageProducer: \"data\"\n",
    "      Channels: [2]\n",
    "      EnableMirror: true\n",
    "    }\n",
    "    label: {\n",
    "      Verbosity:3\n",
    "      ParticleProducer: \"mctruth\"\n",
    "      PdgClassList: [2212,11,211,13,22]\n",
    "    }\n",
    "  }\n",
    "\n",
    "\"\"\"%(path_to_train_data)\n",
    "\n",
    "test_cfg=\"\"\"ThreadProcessorTest: {\n",
    "  Verbosity:3\n",
    "  NumThreads: 2\n",
    "  NumBatchStorage: 2\n",
    "  RandomAccess: true\n",
    "  InputFiles: [\"%s\"]\n",
    "  ProcessName: [\"imagetest\",\"labeltest\"]\n",
    "  ProcessType: [\"BatchFillerImage2D\",\"BatchFillerPIDLabel\"]\n",
    "  ProcessList: {\n",
    "    imagetest: {\n",
    "      Verbosity:3\n",
    "      ImageProducer: \"data\"\n",
    "      Channels: [2]\n",
    "      EnableMirror: false\n",
    "    }\n",
    "    labeltest: {\n",
    "      Verbosity:3\n",
    "      ParticleProducer: \"mctruth\"\n",
    "      PdgClassList: [2212,11,211,13,22]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "\"\"\"%(path_to_test_data)\n",
    "\n",
    "train_cfg_out = open(\"train_dataloader.cfg\",'w')\n",
    "print >> train_cfg_out,train_cfg\n",
    "train_cfg_out.close()\n",
    "\n",
    "test_cfg_out  = open(\"test_dataloader.cfg\",'w')\n",
    "print >> test_cfg_out,test_cfg\n",
    "test_cfg_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Network\n",
    "\n",
    "## Define network\n",
    "\n",
    "We use ResNet-18 as implemented in the torchvision module.  We reproduce it here and make a slight modification: we change the number of input channels from 3 to 1.  The original resnet expects an RGB image.  For our example, we only use the image from one plane from our hypothetical LAr TPC detector.\n",
    "\n",
    "Original can be found [here](https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "# define convolution without bias that we will use throughout the network\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "# implements one ResNet unit\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "# define the network. It provides options for \n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000, input_channels=3):\n",
    "        \"\"\"\n",
    "        inputs\n",
    "        ------\n",
    "        block: type of resnet unit\n",
    "        layers: list of 4 ints. defines number of basic block units in each set of resnet units\n",
    "        num_classes: output classes\n",
    "        input_channels: number of channels in input images\n",
    "        \"\"\"\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        \n",
    "        # had to change stride of avgpool from original from 1 to 2\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=2)\n",
    "\n",
    "        # I've added dropout to the network\n",
    "        self.dropout = nn.Dropout2d(p=0.5,inplace=True)\n",
    "\n",
    "        #print \"block.expansion=\",block.expansion                                                                                                                                                           \n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = self.dropout(x)\n",
    "        #print \"avepool: \",x.data.shape                                                                                                                                                                     \n",
    "        x = x.view(x.size(0), -1)\n",
    "        #print \"view: \",x.data.shape                                                                                                                                                                        \n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "    \n",
    "# define a helper function for ResNet-18\n",
    "def resnet18(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.                                                                                                                                                                        \n",
    "                                                                                                                                                                                                            \n",
    "    Args:                                                                                                                                                                                                   \n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet                                                                                                                                 \n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
