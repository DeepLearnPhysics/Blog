
<!DOCTYPE html>
<html lang="en">
<head>
  <link href='//fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,700,400italic' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" type="text/css" href="http://deeplearnphysics.org/Blog/theme/stylesheet/style.min.css">

  <link rel="stylesheet" type="text/css" href="http://deeplearnphysics.org/Blog/theme/pygments/github.min.css">
  <link rel="stylesheet" type="text/css" href="http://deeplearnphysics.org/Blog/theme/font-awesome/css/font-awesome.min.css">

  <!-- script is a local library -->
  <link href="http://deeplearnphysics.org/Blog/theme/stylesheet/kazunotebook.css" rel="stylesheet">

  <!--  
    <link href="http://deeplearnphysics.org/Blog/theme/stylesheet/[u'kazunotebook.css']" rel="stylesheet">
  -->




  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="robots" content="index, follow" />

    <!-- Chrome, Firefox OS and Opera -->
    <meta name="theme-color" content="#333">
    <!-- Windows Phone -->
    <meta name="msapplication-navbutton-color" content="#333">
    <!-- iOS Safari -->
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

<meta name="author" content="Kazuhiro Terao" />
<meta name="description" content="In this notebook we train a simple, 10-layers deep convolutional neural network for classifying 5 particle images in a simulated LArTPC detecotr available from the public dataset. We use tensorflow to train the network and larcv_threadio to fetch data from larcv files. If you are completely unfamiliar with larcv_threadio, go look at this quick start" />
<meta name="keywords" content="tutorial">
<meta property="og:site_name" content="DeepLearnPhysics Blog"/>
<meta property="og:title" content="Tutorial 05: public data training (classification)"/>
<meta property="og:description" content="In this notebook we train a simple, 10-layers deep convolutional neural network for classifying 5 particle images in a simulated LArTPC detecotr available from the public dataset. We use tensorflow to train the network and larcv_threadio to fetch data from larcv files. If you are completely unfamiliar with larcv_threadio, go look at this quick start"/>
<meta property="og:locale" content="en_US"/>
<meta property="og:url" content="http://deeplearnphysics.org/Blog/tutorial-05.html"/>
<meta property="og:type" content="article"/>
<meta property="article:published_time" content="2017-12-06 00:00:00-06:00"/>
<meta property="article:modified_time" content=""/>
<meta property="article:author" content="http://deeplearnphysics.org/Blog/author/kazuhiro-terao.html">
<meta property="article:section" content="larcv-tutorial"/>
<meta property="article:tag" content="tutorial"/>
<meta property="og:image" content="profile.png">

  <title>DeepLearnPhysics Blog &ndash; Tutorial 05: public data training (classification)</title>
</head>
<body>
  <aside>
    <div>
      <a href="http://deeplearnphysics.org/Blog">
        <img src="http://deeplearnphysics.org/Blog/theme/img/profile.png" alt="Blog" title="Blog">
      </a>
      <h1><a href="http://deeplearnphysics.org/Blog">Blog</a></h1>

<p>DeepLearnPhysics Group</p>

      <ul class="social">
        <li><a class="sc-home" href="http://deeplearnphysics.org" target="_blank"><i class="fa fa-home"></i></a></li>
        <li><a class="sc-github" href="http://github.com/DeepLearnPhysics" target="_blank"><i class="fa fa-github"></i></a></li>
      </ul>
    </div>

  </aside>
  <main>
    <nav>


      <a href="http://deeplearnphysics.org/Blog/index.html">Home</a>
      <a href="http://deeplearnphysics.org/Blog/categories.html">Category</a>
      <a href="http://deeplearnphysics.org/Blog/archives.html">Archives</a>
      <a href="http://deeplearnphysics.org/Blog/tags.html">Tags</a>
      <a href="http://deeplearnphysics.org/Blog/authors.html">Authors</a>


    </nav>

<article class="single">
  <header>
    <h2 id="tutorial-05">Tutorial 05: public data training (classification)</h2>
    <p>
          Posted on Wed 06 December 2017 in <a href="http://deeplearnphysics.org/Blog/category/larcv-tutorial.html">larcv-tutorial</a>


    </p>
  </header>

  <div>
    <style type="text/css">/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI colors. */
.ansibold {
  font-weight: bold;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  border-left-width: 1px;
  padding-left: 5px;
  background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%);
}
div.cell.jupyter-soft-selected {
  border-left-color: #90CAF9;
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected {
  border-color: #ababab;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%);
}
@media print {
  div.cell.selected {
    border-color: transparent;
  }
}
div.cell.selected.jupyter-soft-selected {
  border-left-width: 0;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%);
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%);
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  padding: 0.4em;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */
  /* .CodeMirror-lines */
  padding: 0;
  border: 0;
  border-radius: 0;
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area 
div.output_area 
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}



.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}






.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}








.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}


.rendered_html pre,



.rendered_html tr,
.rendered_html th,

.rendered_html td,


.rendered_html * + table {
  margin-top: 1em;
}

.rendered_html * + p {
  margin-top: 1em;
}

.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,

.rendered_html img.unconfined,

div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered 
.text_cell.unrendered .text_cell_render {
  display: none;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
</style>
<style type="text/css">.highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */</style>
<style type="text/css">
/* Temporary definitions which will become obsolete with Notebook release 5.0 */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }
</style>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In this notebook we train a simple, 10-layers deep convolutional neural network for classifying 5 particle images in a simulated LArTPC detecotr available from the <a href="http://deeplearnphysics.org/DataChallenge">public dataset</a>. We use tensorflow to train the network and <code>larcv_threadio</code> to fetch data from larcv files. If you are completely unfamiliar with <code>larcv_threadio</code>, go look at this <a href="http://deeplearnphysics.org/Blog/tutorial04.html">quick start</a>. First let's prepare data samples. For the setup of this example, I need to prepare <code>practice_train_5k.root</code> and <code>practice_test_5k.root</code> in the current directory. Let us make symbolic links.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span>%%bash
<span class="c1"># Preparation: make symbolic links for practice_train_10k.root and practice_test_10k.root</span>
<span class="nv">PRACTICE_FILE_DIR</span><span class="o">=</span>../..
ln -sf <span class="nv">$PRACTICE_FILE_DIR</span>/practice_train_5k.root ./train.root
ln -sf <span class="nv">$PRACTICE_FILE_DIR</span>/practice_test_5k.root ./test.root
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Imports">Imports<a class="anchor-link" href="#Imports">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="kn">from</span> <span class="nn">larcv</span> <span class="kn">import</span> <span class="n">larcv</span>
<span class="kn">from</span> <span class="nn">larcv.dataloader2</span> <span class="kn">import</span> <span class="n">larcv_threadio</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">os</span><span class="o">,</span><span class="nn">sys</span><span class="o">,</span><span class="nn">time</span>

<span class="c1"># tensorflow/gpu start-up configuration</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;TF_CPP_MIN_LOG_LEVEL&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;3&#39;</span>
<span class="o">%</span><span class="k">env</span> CUDA_DEVICE_ORDER=PCI_BUS_ID
<span class="o">%</span><span class="k">env</span> CUDA_VISIBLE_DEVICES=2
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>env: CUDA_DEVICE_ORDER=PCI_BUS_ID
env: CUDA_VISIBLE_DEVICES=2
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We set <code>os.environ['TF_CPP_MIN_LOG_LEVEL']</code> to suppress lots of <em>non-error</em> (standard) output from tensorflow because it can overwhelm ipython's capability to fetch <code>stdout</code> stream.</p>
<h2 id="Configurations">Configurations<a class="anchor-link" href="#Configurations">&#182;</a></h2><p>Next, let's define configuration variables.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="n">TUTORIAL_DIR</span>     <span class="o">=</span> <span class="s1">&#39;..&#39;</span>
<span class="n">TRAIN_IO_CONFIG</span>  <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">TUTORIAL_DIR</span><span class="p">,</span> <span class="s1">&#39;tf/io_train.cfg&#39;</span><span class="p">)</span>
<span class="n">TEST_IO_CONFIG</span>   <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">TUTORIAL_DIR</span><span class="p">,</span> <span class="s1">&#39;tf/io_test.cfg&#39;</span> <span class="p">)</span>
<span class="n">TRAIN_BATCH_SIZE</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">TEST_BATCH_SIZE</span>  <span class="o">=</span> <span class="mi">100</span>
<span class="n">LOGDIR</span>           <span class="o">=</span> <span class="s1">&#39;log&#39;</span>
<span class="n">ITERATIONS</span>       <span class="o">=</span> <span class="mi">5000</span>
<span class="n">SAVE_SUMMARY</span>     <span class="o">=</span> <span class="mi">20</span>
<span class="n">SAVE_WEIGHTS</span>     <span class="o">=</span> <span class="mi">100</span>

<span class="c1"># Check log directory is empty</span>
<span class="n">train_logdir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">LOGDIR</span><span class="p">,</span><span class="s1">&#39;train&#39;</span><span class="p">)</span>
<span class="n">test_logdir</span>  <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">LOGDIR</span><span class="p">,</span><span class="s1">&#39;test&#39;</span><span class="p">)</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="n">train_logdir</span><span class="p">):</span> <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">train_logdir</span><span class="p">)</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="n">test_logdir</span><span class="p">):</span>  <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">test_logdir</span><span class="p">)</span>
<span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">train_logdir</span><span class="p">))</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">test_logdir</span><span class="p">)):</span>
  <span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s1">&#39;Error: train or test log dir not empty...</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
  <span class="k">raise</span> <span class="ne">OSError</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The top block defines a set of constants in capitalized letters. The bottom part is simply checking if the directories where we will store the network training logs are empty or not (so that we won't mix with the previous attempt). So what do the constants do?</p>
<ul>
<li><code>TUTORIAL_DIR</code> ... points to the top-level directory of the <a href="https://github.com/DeepLearnPhysics/larcv-tutorial">larcv-tutorial</a> repostitory.</li>
<li><code>TRAIN_IO_CONFIG</code> ... a configuration file for <code>larcv_threadio</code> to read data for <strong>training</strong>.</li>
<li><code>TEST_IO_CONFIG</code> ... a configuration file for <code>larcv_threadio</code> to read data for <strong>testing</strong>.</li>
<li><code>TRAIN_BATCH_SIZE</code> ... a number of images (batch) to be used to calculate the average gradients for updating the network's weights.</li>
<li><code>TEST_BATCH_SIZE</code> ... a number of images to be used to calculate the average accuracy using test data set.</li>
<li><code>LOGDIR</code> ... the top-level directory to save the tensorboard logs.</li>
<li><code>ITERATIONS</code> ... the total number of steps (batches) to train the network.</li>
<li><code>SAVE_SUMMARY</code> ... a period in a training step count to save the log (tensorboard summaries).</li>
<li><code>SAVE_WEIGHTS</code> ... a period in a training step count to save the network's weights.</li>
</ul>
<h2 id="Configure-data-reader">Configure data reader<a class="anchor-link" href="#Configure-data-reader">&#182;</a></h2><p>We prepare two data reader instances: one for training and another for testing the network. Testing is not absolutely needed but we try here to just cover in this example. We don't go in details of how <code>larcv_threadio</code> works here since there is <a href="http://deeplearnphysics.org/Blog/tutorial-04.html">a dedicated tutorial</a> for that.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1">#</span>
<span class="c1"># Step 0: IO</span>
<span class="c1">#</span>
<span class="c1"># for &quot;train&quot; data set</span>
<span class="n">train_io</span> <span class="o">=</span> <span class="n">larcv_threadio</span><span class="p">()</span>  <span class="c1"># create io interface</span>
<span class="n">train_io_cfg</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;filler_name&#39;</span> <span class="p">:</span> <span class="s1">&#39;TrainIO&#39;</span><span class="p">,</span>
                <span class="s1">&#39;verbosity&#39;</span>   <span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
                <span class="s1">&#39;filler_cfg&#39;</span>  <span class="p">:</span> <span class="n">TRAIN_IO_CONFIG</span><span class="p">}</span>
<span class="n">train_io</span><span class="o">.</span><span class="n">configure</span><span class="p">(</span><span class="n">train_io_cfg</span><span class="p">)</span>   <span class="c1"># configure</span>
<span class="n">train_io</span><span class="o">.</span><span class="n">start_manager</span><span class="p">(</span><span class="n">TRAIN_BATCH_SIZE</span><span class="p">)</span> <span class="c1"># start read thread</span>
<span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">train_io</span><span class="o">.</span><span class="n">next</span><span class="p">()</span>

<span class="c1"># for &quot;test&quot; data set</span>
<span class="n">test_io</span> <span class="o">=</span> <span class="n">larcv_threadio</span><span class="p">()</span>   <span class="c1"># create io interface</span>
<span class="n">test_io_cfg</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;filler_name&#39;</span> <span class="p">:</span> <span class="s1">&#39;TestIO&#39;</span><span class="p">,</span>
               <span class="s1">&#39;verbosity&#39;</span>   <span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
               <span class="s1">&#39;filler_cfg&#39;</span>  <span class="p">:</span> <span class="n">TEST_IO_CONFIG</span><span class="p">}</span>
<span class="n">test_io</span><span class="o">.</span><span class="n">configure</span><span class="p">(</span><span class="n">test_io_cfg</span><span class="p">)</span>   <span class="c1"># configure</span>
<span class="n">test_io</span><span class="o">.</span><span class="n">start_manager</span><span class="p">(</span><span class="n">TEST_BATCH_SIZE</span><span class="p">)</span> <span class="c1"># start read thread</span>
<span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">test_io</span><span class="o">.</span><span class="n">next</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre><span class="ansi-yellow-intense-fg"> setting verbosity </span>3
<span class="ansi-yellow-intense-fg"> setting verbosity </span>3
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Defining-a-network">Defining a network<a class="anchor-link" href="#Defining-a-network">&#182;</a></h2><p>Let's construct a simple network for this exercise. We use 5x2 convolution layers with max-pooling operation followed after every 2 convolution layers except the last layer is average-pooling.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1">#</span>
<span class="c1"># Step 1: Define network</span>
<span class="c1">#</span>
<span class="kn">import</span> <span class="nn">tensorflow.contrib.slim</span> <span class="kn">as</span> <span class="nn">slim</span>
<span class="kn">import</span> <span class="nn">tensorflow.python.platform</span>

<span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">num_class</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">debug</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>

    <span class="n">net</span> <span class="o">=</span> <span class="n">input_tensor</span>
    <span class="k">if</span> <span class="n">debug</span><span class="p">:</span> <span class="k">print</span><span class="p">(</span><span class="s1">&#39;input tensor:&#39;</span><span class="p">,</span> <span class="n">input_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="n">filters</span> <span class="o">=</span> <span class="mi">32</span>
    <span class="n">num_modules</span> <span class="o">=</span> <span class="mi">5</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s1">&#39;conv&#39;</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
            <span class="n">stride</span> <span class="o">=</span> <span class="mi">2</span>
            <span class="k">if</span> <span class="n">step</span><span class="p">:</span> <span class="n">stride</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="n">net</span> <span class="o">=</span> <span class="n">slim</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">inputs</span>        <span class="o">=</span> <span class="n">net</span><span class="p">,</span>        <span class="c1"># input tensor</span>
                              <span class="n">num_outputs</span>   <span class="o">=</span> <span class="n">filters</span><span class="p">,</span>    <span class="c1"># number of filters (neurons) = # of output feature maps</span>
                              <span class="n">kernel_size</span>   <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span>      <span class="c1"># kernel size</span>
                              <span class="n">stride</span>        <span class="o">=</span> <span class="n">stride</span><span class="p">,</span>     <span class="c1"># stride size</span>
                              <span class="n">trainable</span>     <span class="o">=</span> <span class="n">trainable</span><span class="p">,</span>  <span class="c1"># train or inference</span>
                              <span class="n">activation_fn</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span> <span class="c1"># relu</span>
                              <span class="n">scope</span>         <span class="o">=</span> <span class="s1">&#39;conv</span><span class="si">%d</span><span class="s1">a_conv&#39;</span> <span class="o">%</span> <span class="n">step</span><span class="p">)</span>

            <span class="n">net</span> <span class="o">=</span> <span class="n">slim</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">inputs</span>        <span class="o">=</span> <span class="n">net</span><span class="p">,</span>        <span class="c1"># input tensor</span>
                              <span class="n">num_outputs</span>   <span class="o">=</span> <span class="n">filters</span><span class="p">,</span>    <span class="c1"># number of filters (neurons) = # of output feature maps</span>
                              <span class="n">kernel_size</span>   <span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span>      <span class="c1"># kernel size</span>
                              <span class="n">stride</span>        <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>          <span class="c1"># stride size</span>
                              <span class="n">trainable</span>     <span class="o">=</span> <span class="n">trainable</span><span class="p">,</span>  <span class="c1"># train or inference</span>
                              <span class="n">activation_fn</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span> <span class="c1"># relu</span>
                              <span class="n">scope</span>         <span class="o">=</span> <span class="s1">&#39;conv</span><span class="si">%d</span><span class="s1">b_conv&#39;</span> <span class="o">%</span> <span class="n">step</span><span class="p">)</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">step</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">num_modules</span><span class="p">:</span>
                <span class="n">net</span> <span class="o">=</span> <span class="n">slim</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">inputs</span>      <span class="o">=</span> <span class="n">net</span><span class="p">,</span>    <span class="c1"># input tensor</span>
                                      <span class="n">kernel_size</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span>  <span class="c1"># kernel size</span>
                                      <span class="n">stride</span>      <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>      <span class="c1"># stride size</span>
                                      <span class="n">scope</span>       <span class="o">=</span> <span class="s1">&#39;conv</span><span class="si">%d</span><span class="s1">_pool&#39;</span> <span class="o">%</span> <span class="n">step</span><span class="p">)</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="n">net</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">average_pooling2d</span><span class="p">(</span><span class="n">inputs</span> <span class="o">=</span> <span class="n">net</span><span class="p">,</span>
                                                  <span class="n">pool_size</span> <span class="o">=</span> <span class="p">[</span><span class="n">net</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">value</span><span class="p">,</span><span class="n">net</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()[</span><span class="o">-</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">value</span><span class="p">],</span>
                                                  <span class="n">strides</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
                                                  <span class="n">padding</span> <span class="o">=</span> <span class="s1">&#39;valid&#39;</span><span class="p">,</span>
                                                  <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;conv</span><span class="si">%d</span><span class="s1">_pool&#39;</span> <span class="o">%</span> <span class="n">step</span><span class="p">)</span>
            <span class="n">filters</span> <span class="o">*=</span> <span class="mi">2</span>

            <span class="k">if</span> <span class="n">debug</span><span class="p">:</span> <span class="k">print</span><span class="p">(</span><span class="s1">&#39;After step&#39;</span><span class="p">,</span><span class="n">step</span><span class="p">,</span><span class="s1">&#39;shape&#39;</span><span class="p">,</span><span class="n">net</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s1">&#39;final&#39;</span><span class="p">):</span>
        <span class="n">net</span> <span class="o">=</span> <span class="n">slim</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">scope</span><span class="o">=</span><span class="s1">&#39;flatten&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">debug</span><span class="p">:</span> <span class="k">print</span><span class="p">(</span><span class="s1">&#39;After flattening&#39;</span><span class="p">,</span> <span class="n">net</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

        <span class="n">net</span> <span class="o">=</span> <span class="n">slim</span><span class="o">.</span><span class="n">fully_connected</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">num_class</span><span class="p">),</span> <span class="n">scope</span><span class="o">=</span><span class="s1">&#39;final_fc&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">debug</span><span class="p">:</span> <span class="k">print</span><span class="p">(</span><span class="s1">&#39;After final_fc&#39;</span><span class="p">,</span> <span class="n">net</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">net</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Build-the-network">Build the network<a class="anchor-link" href="#Build-the-network">&#182;</a></h2><p>Build the network and define loss, accuracy metrics and our solver. Any optimizer should work but you may have to tune the parameters by yourself. Here, we use <code>RMSPropOptimizer</code> with base learning rate <code>0.0005</code> with no justification. Note we add minimal set of tensorflow variables into tf.summary to demonstrate later the <code>tensorboard</code>, a dedicated monitoring/visualization tool for network training with tensorflow.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1">#</span>
<span class="c1"># Step 2: Build network + define loss &amp; solver</span>
<span class="c1">#</span>
<span class="c1"># retrieve dimensions of data for network construction</span>
<span class="n">dim_data</span>  <span class="o">=</span> <span class="n">train_io</span><span class="o">.</span><span class="n">fetch_data</span><span class="p">(</span><span class="s1">&#39;train_image&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span>
<span class="n">dim_label</span> <span class="o">=</span> <span class="n">train_io</span><span class="o">.</span><span class="n">fetch_data</span><span class="p">(</span><span class="s1">&#39;train_label&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span>
<span class="c1"># define place holders</span>
<span class="n">data_tensor</span>    <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="n">dim_data</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">dim_data</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">dim_data</span><span class="p">[</span><span class="mi">3</span><span class="p">]],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;image&#39;</span><span class="p">)</span>
<span class="n">label_tensor</span>   <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="n">dim_label</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;label&#39;</span><span class="p">)</span>
<span class="n">data_tensor_2d</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">data_tensor</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">dim_data</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">dim_data</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span><span class="n">dim_data</span><span class="p">[</span><span class="mi">3</span><span class="p">]],</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;image_reshape&#39;</span><span class="p">)</span>

<span class="c1"># Let&#39;s keep 10 random set of images in the log</span>
<span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">image</span><span class="p">(</span><span class="s1">&#39;input&#39;</span><span class="p">,</span><span class="n">data_tensor_2d</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span>
<span class="c1"># build net</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">build</span><span class="p">(</span><span class="n">input_tensor</span><span class="o">=</span><span class="n">data_tensor_2d</span><span class="p">,</span> <span class="n">num_class</span><span class="o">=</span><span class="n">dim_label</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">trainable</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">debug</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="c1"># Define accuracy</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;accuracy&#39;</span><span class="p">):</span>
    <span class="n">correct_prediction</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">net</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">label_tensor</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">correct_prediction</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s1">&#39;accuracy&#39;</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>
<span class="c1"># Define loss + backprop as training step</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s1">&#39;train&#39;</span><span class="p">):</span>
    <span class="n">cross_entropy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax_cross_entropy_with_logits</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="n">label_tensor</span><span class="p">,</span> <span class="n">logits</span><span class="o">=</span><span class="n">net</span><span class="p">))</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s1">&#39;cross_entropy&#39;</span><span class="p">,</span><span class="n">cross_entropy</span><span class="p">)</span>
    <span class="n">train_step</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">RMSPropOptimizer</span><span class="p">(</span><span class="mf">0.00005</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">cross_entropy</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Defining-tensorflow-IO">Defining tensorflow IO<a class="anchor-link" href="#Defining-tensorflow-IO">&#182;</a></h2><p>In the next cell we define tensorflow's IO</p>
<ul>
<li><code>merged_summary</code> ... is tensorflow operation to create summaries to be written into a <em>log file</em> for <code>tensorboard</code>.</li>
<li><code>writer_train</code> ... writes monitoring data for training data sample into a log file.</li>
<li><code>writer_test</code> ... is same as <code>writer_train</code> except it is for testing data sample.</li>
<li><code>saver</code> ... is a handle to store the state of the network = trained network variable values (weights, biases, etc.).</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1">#                                                                                                                                      </span>
<span class="c1"># Step 3: weight saver &amp; summary writer                                                                                                </span>
<span class="c1">#                                                                                                                                      </span>
<span class="c1"># Create a bandle of summary                                                                                                           </span>
<span class="n">merged_summary</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">merge_all</span><span class="p">()</span>
<span class="c1"># Create a session                                                                                                                     </span>
<span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">InteractiveSession</span><span class="p">()</span>
<span class="c1"># Initialize variables                                                                                                                 </span>
<span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>
<span class="c1"># Create a summary writer handle                                                                                                       </span>
<span class="n">writer_train</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">FileWriter</span><span class="p">(</span><span class="n">train_logdir</span><span class="p">)</span>
<span class="n">writer_train</span><span class="o">.</span><span class="n">add_graph</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>
<span class="n">writer_test</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">FileWriter</span><span class="p">(</span><span class="n">test_logdir</span><span class="p">)</span>
<span class="n">writer_test</span><span class="o">.</span><span class="n">add_graph</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>
<span class="c1"># Create weights saver                                                                                                                 </span>
<span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Train!">Train!<a class="anchor-link" href="#Train!">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span><span class="c1">#</span>
<span class="c1"># Step 4: Run training loop</span>
<span class="c1">#</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ITERATIONS</span><span class="p">):</span>

    <span class="n">train_data</span>  <span class="o">=</span> <span class="n">train_io</span><span class="o">.</span><span class="n">fetch_data</span><span class="p">(</span><span class="s1">&#39;train_image&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">data</span><span class="p">()</span>
    <span class="n">train_label</span> <span class="o">=</span> <span class="n">train_io</span><span class="o">.</span><span class="n">fetch_data</span><span class="p">(</span><span class="s1">&#39;train_label&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">data</span><span class="p">()</span>

    <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span> <span class="n">data_tensor</span>  <span class="p">:</span> <span class="n">train_data</span><span class="p">,</span>
                  <span class="n">label_tensor</span> <span class="p">:</span> <span class="n">train_label</span> <span class="p">}</span>

    <span class="n">loss</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">cross_entropy</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">,</span> <span class="n">train_step</span><span class="p">],</span> <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed_dict</span><span class="p">)</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">%</span><span class="k">SAVE_SUMMARY</span> == 0:
        <span class="c1"># Save train log</span>
        <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s1">&#39;Training in progress @ step </span><span class="si">%d</span><span class="s1"> loss </span><span class="si">%g</span><span class="s1"> accuracy </span><span class="si">%g</span><span class="s1">          </span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">loss</span><span class="p">,</span><span class="n">acc</span><span class="p">))</span>
        <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>
        <span class="n">s</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">merged_summary</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed_dict</span><span class="p">)</span>
        <span class="n">writer_train</span><span class="o">.</span><span class="n">add_summary</span><span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="n">i</span><span class="p">)</span>
    
        <span class="c1"># Calculate &amp; save test log</span>
        <span class="n">test_data</span>  <span class="o">=</span> <span class="n">test_io</span><span class="o">.</span><span class="n">fetch_data</span><span class="p">(</span><span class="s1">&#39;test_image&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">data</span><span class="p">()</span>
        <span class="n">test_label</span> <span class="o">=</span> <span class="n">test_io</span><span class="o">.</span><span class="n">fetch_data</span><span class="p">(</span><span class="s1">&#39;test_label&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">data</span><span class="p">()</span>
        <span class="n">feed_dict</span>  <span class="o">=</span> <span class="p">{</span> <span class="n">data_tensor</span>  <span class="p">:</span> <span class="n">test_data</span><span class="p">,</span>
                       <span class="n">label_tensor</span> <span class="p">:</span> <span class="n">test_label</span> <span class="p">}</span>
        <span class="n">loss</span><span class="p">,</span> <span class="n">acc</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">cross_entropy</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">],</span> <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed_dict</span><span class="p">)</span>
        <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s1">&#39;Testing in progress @ step </span><span class="si">%d</span><span class="s1"> loss </span><span class="si">%g</span><span class="s1"> accuracy </span><span class="si">%g</span><span class="s1">          </span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">loss</span><span class="p">,</span><span class="n">acc</span><span class="p">))</span>
        <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>
        <span class="n">s</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">merged_summary</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed_dict</span><span class="p">)</span>
        <span class="n">writer_test</span><span class="o">.</span><span class="n">add_summary</span><span class="p">(</span><span class="n">s</span><span class="p">,</span><span class="n">i</span><span class="p">)</span>
        
        <span class="n">test_io</span><span class="o">.</span><span class="n">next</span><span class="p">()</span>

    <span class="n">train_io</span><span class="o">.</span><span class="n">next</span><span class="p">()</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">%</span><span class="k">SAVE_WEIGHTS</span> == 0:
        <span class="n">ssf_path</span> <span class="o">=</span> <span class="n">saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span><span class="s1">&#39;weights/toynet&#39;</span><span class="p">,</span><span class="n">global_step</span><span class="o">=</span><span class="n">i</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;saved @&#39;</span><span class="p">,</span><span class="n">ssf_path</span><span class="p">)</span>

<span class="c1"># inform log directory</span>
<span class="k">print</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Run `tensorboard --logdir=</span><span class="si">%s</span><span class="s1">` in terminal to see the results.&#39;</span> <span class="o">%</span> <span class="n">LOGDIR</span><span class="p">)</span>
<span class="n">train_io</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<span class="n">test_io</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

<div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Training in progress @ step 19 loss 1.60804 accuracy 0.22          
Testing in progress @ step 19 loss 1.61259 accuracy 0.19          
Training in progress @ step 39 loss 1.59938 accuracy 0.28          
Testing in progress @ step 39 loss 1.61911 accuracy 0.14          
Training in progress @ step 59 loss 1.60463 accuracy 0.1          
Testing in progress @ step 59 loss 1.60371 accuracy 0.27          
Training in progress @ step 79 loss 1.60484 accuracy 0.18          
Testing in progress @ step 79 loss 1.61089 accuracy 0.13          
Training in progress @ step 99 loss 1.56293 accuracy 0.28          
Testing in progress @ step 99 loss 1.57563 accuracy 0.24          
saved @ weights/toynet-99
Training in progress @ step 119 loss 1.58767 accuracy 0.24          
Testing in progress @ step 119 loss 1.61108 accuracy 0.19          
Training in progress @ step 139 loss 1.55079 accuracy 0.3          
Testing in progress @ step 139 loss 1.56534 accuracy 0.34          
Training in progress @ step 159 loss 1.41064 accuracy 0.4          
Testing in progress @ step 159 loss 1.51217 accuracy 0.37          
Training in progress @ step 179 loss 1.49059 accuracy 0.42          
Testing in progress @ step 179 loss 1.4979 accuracy 0.3          
Training in progress @ step 199 loss 1.56263 accuracy 0.24          
Testing in progress @ step 199 loss 1.49698 accuracy 0.34          
saved @ weights/toynet-199
Training in progress @ step 219 loss 1.42051 accuracy 0.38          
Testing in progress @ step 219 loss 1.40418 accuracy 0.36          
Training in progress @ step 239 loss 1.42 accuracy 0.34          
Testing in progress @ step 239 loss 1.35263 accuracy 0.42          
Training in progress @ step 259 loss 1.23509 accuracy 0.52          
Testing in progress @ step 259 loss 1.34543 accuracy 0.35          
Training in progress @ step 279 loss 1.33113 accuracy 0.46          
Testing in progress @ step 279 loss 1.30162 accuracy 0.49          
Training in progress @ step 299 loss 1.63349 accuracy 0.3          
Testing in progress @ step 299 loss 1.46306 accuracy 0.38          
saved @ weights/toynet-299
Training in progress @ step 319 loss 1.31014 accuracy 0.46          
Testing in progress @ step 319 loss 1.34693 accuracy 0.44          
Training in progress @ step 339 loss 1.03612 accuracy 0.66          
Testing in progress @ step 339 loss 1.45878 accuracy 0.41          
Training in progress @ step 359 loss 1.23237 accuracy 0.5          
Testing in progress @ step 359 loss 1.22048 accuracy 0.52          
Training in progress @ step 379 loss 1.31127 accuracy 0.46          
Testing in progress @ step 379 loss 1.29868 accuracy 0.45          
Training in progress @ step 399 loss 1.49949 accuracy 0.32          
Testing in progress @ step 399 loss 1.27982 accuracy 0.48          
saved @ weights/toynet-399
Training in progress @ step 419 loss 1.15013 accuracy 0.56          
Testing in progress @ step 419 loss 1.27892 accuracy 0.45          
Training in progress @ step 439 loss 0.865968 accuracy 0.66          
Testing in progress @ step 439 loss 1.15786 accuracy 0.5          
Training in progress @ step 459 loss 1.54451 accuracy 0.38          
Testing in progress @ step 459 loss 1.38144 accuracy 0.41          
Training in progress @ step 479 loss 1.20095 accuracy 0.48          
Testing in progress @ step 479 loss 1.19787 accuracy 0.46          
Training in progress @ step 499 loss 1.06143 accuracy 0.48          
Testing in progress @ step 499 loss 1.31291 accuracy 0.45          
saved @ weights/toynet-499
Training in progress @ step 519 loss 1.20675 accuracy 0.48          
Testing in progress @ step 519 loss 1.13593 accuracy 0.54          
Training in progress @ step 539 loss 0.780554 accuracy 0.66          
Testing in progress @ step 539 loss 1.21183 accuracy 0.48          
Training in progress @ step 559 loss 1.10059 accuracy 0.58          
Testing in progress @ step 559 loss 1.07109 accuracy 0.5          
Training in progress @ step 579 loss 1.13958 accuracy 0.5          
Testing in progress @ step 579 loss 1.25944 accuracy 0.45          
Training in progress @ step 599 loss 0.982788 accuracy 0.56          
Testing in progress @ step 599 loss 1.16895 accuracy 0.47          
saved @ weights/toynet-599
Training in progress @ step 619 loss 1.16153 accuracy 0.54          
Testing in progress @ step 619 loss 1.23791 accuracy 0.54          
Training in progress @ step 639 loss 1.1081 accuracy 0.46          
Testing in progress @ step 639 loss 1.15263 accuracy 0.55          
Training in progress @ step 659 loss 1.02257 accuracy 0.62          
Testing in progress @ step 659 loss 1.12234 accuracy 0.52          
Training in progress @ step 679 loss 1.1435 accuracy 0.5          
Testing in progress @ step 679 loss 1.13025 accuracy 0.43          
Training in progress @ step 699 loss 1.67424 accuracy 0.3          
Testing in progress @ step 699 loss 1.36547 accuracy 0.43          
saved @ weights/toynet-699
Training in progress @ step 719 loss 1.21574 accuracy 0.56          
Testing in progress @ step 719 loss 1.27319 accuracy 0.49          
Training in progress @ step 739 loss 1.10817 accuracy 0.48          
Testing in progress @ step 739 loss 1.06292 accuracy 0.6          
Training in progress @ step 759 loss 0.988775 accuracy 0.62          
Testing in progress @ step 759 loss 1.02028 accuracy 0.5          
Training in progress @ step 779 loss 1.07787 accuracy 0.58          
Testing in progress @ step 779 loss 1.07664 accuracy 0.48          
Training in progress @ step 799 loss 0.924829 accuracy 0.58          
Testing in progress @ step 799 loss 1.16148 accuracy 0.51          
saved @ weights/toynet-799
Training in progress @ step 819 loss 1.02027 accuracy 0.58          
Testing in progress @ step 819 loss 1.06231 accuracy 0.44          
Training in progress @ step 839 loss 1.08011 accuracy 0.48          
Testing in progress @ step 839 loss 0.939656 accuracy 0.51          
Training in progress @ step 859 loss 1.09139 accuracy 0.56          
Testing in progress @ step 859 loss 1.40887 accuracy 0.48          
Training in progress @ step 879 loss 1.06985 accuracy 0.54          
Testing in progress @ step 879 loss 0.946764 accuracy 0.55          
Training in progress @ step 899 loss 1.26168 accuracy 0.4          
Testing in progress @ step 899 loss 1.02387 accuracy 0.55          
saved @ weights/toynet-899
Training in progress @ step 919 loss 0.985469 accuracy 0.58          
Testing in progress @ step 919 loss 0.913799 accuracy 0.62          
Training in progress @ step 939 loss 0.851035 accuracy 0.64          
Testing in progress @ step 939 loss 0.912754 accuracy 0.56          
Training in progress @ step 959 loss 0.919744 accuracy 0.66          
Testing in progress @ step 959 loss 0.927394 accuracy 0.55          
Training in progress @ step 979 loss 0.888268 accuracy 0.62          
Testing in progress @ step 979 loss 0.854074 accuracy 0.6          
Training in progress @ step 999 loss 0.792844 accuracy 0.62          
Testing in progress @ step 999 loss 0.876297 accuracy 0.62          
saved @ weights/toynet-999
Training in progress @ step 1019 loss 0.923724 accuracy 0.58          
Testing in progress @ step 1019 loss 0.982102 accuracy 0.52          
Training in progress @ step 1039 loss 0.85751 accuracy 0.64          
Testing in progress @ step 1039 loss 1.02859 accuracy 0.56          
Training in progress @ step 1059 loss 0.91098 accuracy 0.62          
Testing in progress @ step 1059 loss 0.747974 accuracy 0.64          
Training in progress @ step 1079 loss 0.854377 accuracy 0.6          
Testing in progress @ step 1079 loss 0.921234 accuracy 0.6          
Training in progress @ step 1099 loss 1.16292 accuracy 0.38          
Testing in progress @ step 1099 loss 0.960073 accuracy 0.52          
saved @ weights/toynet-1099
Training in progress @ step 1119 loss 0.845744 accuracy 0.6          
Testing in progress @ step 1119 loss 0.912497 accuracy 0.59          
Training in progress @ step 1139 loss 0.569651 accuracy 0.7          
Testing in progress @ step 1139 loss 0.772228 accuracy 0.63          
Training in progress @ step 1159 loss 0.897686 accuracy 0.62          
Testing in progress @ step 1159 loss 0.799776 accuracy 0.64          
Training in progress @ step 1179 loss 0.842747 accuracy 0.62          
Testing in progress @ step 1179 loss 1.09458 accuracy 0.52          
Training in progress @ step 1199 loss 1.40838 accuracy 0.32          
Testing in progress @ step 1199 loss 0.960923 accuracy 0.61          
saved @ weights/toynet-1199
Training in progress @ step 1219 loss 0.837344 accuracy 0.74          
Testing in progress @ step 1219 loss 0.89485 accuracy 0.63          
Training in progress @ step 1239 loss 0.627333 accuracy 0.74          
Testing in progress @ step 1239 loss 0.902356 accuracy 0.57          
Training in progress @ step 1259 loss 0.889504 accuracy 0.68          
Testing in progress @ step 1259 loss 0.889847 accuracy 0.59          
Training in progress @ step 1279 loss 0.780373 accuracy 0.64          
Testing in progress @ step 1279 loss 0.807954 accuracy 0.66          
Training in progress @ step 1299 loss 0.746441 accuracy 0.62          
Testing in progress @ step 1299 loss 0.794658 accuracy 0.65          
saved @ weights/toynet-1299
Training in progress @ step 1319 loss 0.871986 accuracy 0.58          
Testing in progress @ step 1319 loss 0.988803 accuracy 0.55          
Training in progress @ step 1339 loss 0.60549 accuracy 0.74          
Testing in progress @ step 1339 loss 0.917192 accuracy 0.54          
Training in progress @ step 1359 loss 0.913408 accuracy 0.54          
Testing in progress @ step 1359 loss 0.850111 accuracy 0.56          
Training in progress @ step 1379 loss 0.775041 accuracy 0.62          
Testing in progress @ step 1379 loss 0.848526 accuracy 0.61          
Training in progress @ step 1399 loss 0.731224 accuracy 0.62          
Testing in progress @ step 1399 loss 1.04472 accuracy 0.58          
saved @ weights/toynet-1399
Training in progress @ step 1419 loss 0.809716 accuracy 0.66          
Testing in progress @ step 1419 loss 0.828566 accuracy 0.61          
Training in progress @ step 1439 loss 0.620828 accuracy 0.7          
Testing in progress @ step 1439 loss 0.839731 accuracy 0.57          
Training in progress @ step 1459 loss 0.883545 accuracy 0.56          
Testing in progress @ step 1459 loss 0.774318 accuracy 0.64          
Training in progress @ step 1479 loss 0.782009 accuracy 0.62          
Testing in progress @ step 1479 loss 0.80091 accuracy 0.63          
Training in progress @ step 1499 loss 0.715672 accuracy 0.64          
Testing in progress @ step 1499 loss 0.800926 accuracy 0.67          
saved @ weights/toynet-1499
Training in progress @ step 1519 loss 0.794199 accuracy 0.7          
Testing in progress @ step 1519 loss 0.899569 accuracy 0.61          
Training in progress @ step 1539 loss 0.56989 accuracy 0.76          
Testing in progress @ step 1539 loss 0.813612 accuracy 0.67          
Training in progress @ step 1559 loss 0.802496 accuracy 0.68          
Testing in progress @ step 1559 loss 0.800578 accuracy 0.62          
Training in progress @ step 1579 loss 0.76987 accuracy 0.68          
Testing in progress @ step 1579 loss 0.985612 accuracy 0.6          
Training in progress @ step 1599 loss 1.0418 accuracy 0.46          
Testing in progress @ step 1599 loss 0.884355 accuracy 0.67          
saved @ weights/toynet-1599
Training in progress @ step 1619 loss 0.788766 accuracy 0.66          
Testing in progress @ step 1619 loss 0.815026 accuracy 0.65          
Training in progress @ step 1639 loss 0.869168 accuracy 0.64          
Testing in progress @ step 1639 loss 0.952737 accuracy 0.59          
Training in progress @ step 1659 loss 0.806298 accuracy 0.7          
Testing in progress @ step 1659 loss 0.7895 accuracy 0.64          
Training in progress @ step 1679 loss 0.799824 accuracy 0.66          
Testing in progress @ step 1679 loss 0.870121 accuracy 0.56          
Training in progress @ step 1699 loss 1.05948 accuracy 0.46          
Testing in progress @ step 1699 loss 0.786247 accuracy 0.72          
saved @ weights/toynet-1699
Training in progress @ step 1719 loss 0.73907 accuracy 0.68          
Testing in progress @ step 1719 loss 0.845045 accuracy 0.57          
Training in progress @ step 1739 loss 0.609573 accuracy 0.72          
Testing in progress @ step 1739 loss 0.874041 accuracy 0.64          
Training in progress @ step 1759 loss 0.799591 accuracy 0.66          
Testing in progress @ step 1759 loss 0.868031 accuracy 0.53          
Training in progress @ step 1779 loss 0.74723 accuracy 0.68          
Testing in progress @ step 1779 loss 0.840827 accuracy 0.63          
Training in progress @ step 1799 loss 1.1167 accuracy 0.46          
Testing in progress @ step 1799 loss 0.819905 accuracy 0.64          
saved @ weights/toynet-1799
Training in progress @ step 1819 loss 0.736943 accuracy 0.68          
Testing in progress @ step 1819 loss 0.841028 accuracy 0.56          
Training in progress @ step 1839 loss 0.587976 accuracy 0.72          
Testing in progress @ step 1839 loss 0.836034 accuracy 0.6          
Training in progress @ step 1859 loss 1.04782 accuracy 0.58          
Testing in progress @ step 1859 loss 0.940606 accuracy 0.57          
Training in progress @ step 1879 loss 0.771269 accuracy 0.68          
Testing in progress @ step 1879 loss 0.821382 accuracy 0.58          
Training in progress @ step 1899 loss 1.0323 accuracy 0.4          
Testing in progress @ step 1899 loss 0.961747 accuracy 0.6          
saved @ weights/toynet-1899
Training in progress @ step 1919 loss 0.759074 accuracy 0.7          
Testing in progress @ step 1919 loss 0.664692 accuracy 0.72          
Training in progress @ step 1939 loss 0.777342 accuracy 0.64          
Testing in progress @ step 1939 loss 0.764626 accuracy 0.64          
Training in progress @ step 1959 loss 0.892178 accuracy 0.54          
Testing in progress @ step 1959 loss 0.868235 accuracy 0.54          
Training in progress @ step 1979 loss 0.778631 accuracy 0.64          
Testing in progress @ step 1979 loss 0.884256 accuracy 0.61          
Training in progress @ step 1999 loss 0.997717 accuracy 0.48          
Testing in progress @ step 1999 loss 0.72596 accuracy 0.68          
saved @ weights/toynet-1999
Training in progress @ step 2019 loss 0.722517 accuracy 0.68          
Testing in progress @ step 2019 loss 0.845509 accuracy 0.59          
Training in progress @ step 2039 loss 0.611634 accuracy 0.68          
Testing in progress @ step 2039 loss 0.964 accuracy 0.65          
Training in progress @ step 2059 loss 0.904469 accuracy 0.6          
Testing in progress @ step 2059 loss 0.681892 accuracy 0.66          
Training in progress @ step 2079 loss 0.761023 accuracy 0.68          
Testing in progress @ step 2079 loss 0.74166 accuracy 0.67          
Training in progress @ step 2099 loss 1.04678 accuracy 0.4          
Testing in progress @ step 2099 loss 0.786077 accuracy 0.59          
saved @ weights/toynet-2099
Training in progress @ step 2119 loss 0.706591 accuracy 0.68          
Testing in progress @ step 2119 loss 0.822638 accuracy 0.59          
Training in progress @ step 2139 loss 0.731965 accuracy 0.66          
Testing in progress @ step 2139 loss 0.650216 accuracy 0.71          
Training in progress @ step 2159 loss 0.82419 accuracy 0.6          
Testing in progress @ step 2159 loss 0.63992 accuracy 0.73          
Training in progress @ step 2179 loss 0.75396 accuracy 0.68          
Testing in progress @ step 2179 loss 1.04561 accuracy 0.52          
Training in progress @ step 2199 loss 0.655408 accuracy 0.7          
Testing in progress @ step 2199 loss 0.844042 accuracy 0.67          
saved @ weights/toynet-2199
Training in progress @ step 2219 loss 0.668467 accuracy 0.8          
Testing in progress @ step 2219 loss 0.750227 accuracy 0.65          
Training in progress @ step 2239 loss 0.873769 accuracy 0.66          
Testing in progress @ step 2239 loss 0.777166 accuracy 0.63          
Training in progress @ step 2259 loss 0.84647 accuracy 0.56          
Testing in progress @ step 2259 loss 0.789617 accuracy 0.67          
Training in progress @ step 2279 loss 0.681089 accuracy 0.7          
Testing in progress @ step 2279 loss 0.764521 accuracy 0.68          
Training in progress @ step 2299 loss 1.00233 accuracy 0.52          
Testing in progress @ step 2299 loss 0.768911 accuracy 0.63          
saved @ weights/toynet-2299
Training in progress @ step 2319 loss 0.710802 accuracy 0.7          
Testing in progress @ step 2319 loss 0.895237 accuracy 0.61          
Training in progress @ step 2339 loss 0.771297 accuracy 0.64          
Testing in progress @ step 2339 loss 0.826053 accuracy 0.67          
Training in progress @ step 2359 loss 0.816656 accuracy 0.62          
Testing in progress @ step 2359 loss 0.868144 accuracy 0.63          
Training in progress @ step 2379 loss 0.665603 accuracy 0.72          
Testing in progress @ step 2379 loss 0.761712 accuracy 0.7          
Training in progress @ step 2399 loss 0.943084 accuracy 0.52          
Testing in progress @ step 2399 loss 0.89798 accuracy 0.59          
saved @ weights/toynet-2399
Training in progress @ step 2419 loss 0.6713 accuracy 0.68          
Testing in progress @ step 2419 loss 0.768299 accuracy 0.63          
Training in progress @ step 2439 loss 0.604608 accuracy 0.74          
Testing in progress @ step 2439 loss 0.759793 accuracy 0.64          
Training in progress @ step 2459 loss 0.878221 accuracy 0.62          
Testing in progress @ step 2459 loss 0.943683 accuracy 0.64          
Training in progress @ step 2479 loss 0.655328 accuracy 0.68          
Testing in progress @ step 2479 loss 0.674722 accuracy 0.71          
Training in progress @ step 2499 loss 0.631793 accuracy 0.76          
Testing in progress @ step 2499 loss 0.726522 accuracy 0.68          
saved @ weights/toynet-2499
Training in progress @ step 2519 loss 0.645802 accuracy 0.74          
Testing in progress @ step 2519 loss 0.813128 accuracy 0.66          
Training in progress @ step 2539 loss 0.582686 accuracy 0.72          
Testing in progress @ step 2539 loss 0.753299 accuracy 0.69          
Training in progress @ step 2559 loss 0.862092 accuracy 0.58          
Testing in progress @ step 2559 loss 0.649019 accuracy 0.74          
Training in progress @ step 2579 loss 0.703706 accuracy 0.74          
Testing in progress @ step 2579 loss 1.05466 accuracy 0.64          
Training in progress @ step 2599 loss 0.991806 accuracy 0.52          
Testing in progress @ step 2599 loss 0.772276 accuracy 0.7          
saved @ weights/toynet-2599
Training in progress @ step 2619 loss 0.61569 accuracy 0.72          
Testing in progress @ step 2619 loss 0.762828 accuracy 0.62          
Training in progress @ step 2639 loss 0.681346 accuracy 0.68          
Testing in progress @ step 2639 loss 1.0182 accuracy 0.66          
Training in progress @ step 2659 loss 0.734712 accuracy 0.68          
Testing in progress @ step 2659 loss 0.751037 accuracy 0.65          
Training in progress @ step 2679 loss 0.720828 accuracy 0.68          
Testing in progress @ step 2679 loss 0.822734 accuracy 0.63          
Training in progress @ step 2699 loss 0.606319 accuracy 0.74          
Testing in progress @ step 2699 loss 0.873934 accuracy 0.71          
saved @ weights/toynet-2699
Training in progress @ step 2719 loss 0.638485 accuracy 0.72          
Testing in progress @ step 2719 loss 0.838632 accuracy 0.61          
Training in progress @ step 2739 loss 0.582639 accuracy 0.72          
Testing in progress @ step 2739 loss 0.839116 accuracy 0.69          
Training in progress @ step 2759 loss 0.723348 accuracy 0.66          
Testing in progress @ step 2759 loss 0.781844 accuracy 0.58          
Training in progress @ step 2779 loss 0.804298 accuracy 0.62          
Testing in progress @ step 2779 loss 0.781691 accuracy 0.7          
Training in progress @ step 2799 loss 0.566278 accuracy 0.78          
Testing in progress @ step 2799 loss 0.629277 accuracy 0.68          
saved @ weights/toynet-2799
Training in progress @ step 2819 loss 0.598975 accuracy 0.7          
Testing in progress @ step 2819 loss 0.72805 accuracy 0.63          
Training in progress @ step 2839 loss 0.640852 accuracy 0.7          
Testing in progress @ step 2839 loss 0.827767 accuracy 0.64          
Training in progress @ step 2859 loss 0.748543 accuracy 0.64          
Testing in progress @ step 2859 loss 1.01029 accuracy 0.6          
Training in progress @ step 2879 loss 0.646093 accuracy 0.76          
Testing in progress @ step 2879 loss 0.717815 accuracy 0.67          
Training in progress @ step 2899 loss 0.594118 accuracy 0.78          
Testing in progress @ step 2899 loss 1.0105 accuracy 0.61          
saved @ weights/toynet-2899
Training in progress @ step 2919 loss 0.647871 accuracy 0.72          
Testing in progress @ step 2919 loss 0.680736 accuracy 0.72          
Training in progress @ step 2939 loss 0.579024 accuracy 0.76          
Testing in progress @ step 2939 loss 0.810344 accuracy 0.62          
Training in progress @ step 2959 loss 0.687057 accuracy 0.72          
Testing in progress @ step 2959 loss 0.968042 accuracy 0.6          
Training in progress @ step 2979 loss 0.605305 accuracy 0.74          
Testing in progress @ step 2979 loss 0.766425 accuracy 0.67          
Training in progress @ step 2999 loss 0.865925 accuracy 0.52          
Testing in progress @ step 2999 loss 0.760901 accuracy 0.64          
saved @ weights/toynet-2999
Training in progress @ step 3019 loss 0.597984 accuracy 0.7          
Testing in progress @ step 3019 loss 0.896497 accuracy 0.58          
Training in progress @ step 3039 loss 0.627448 accuracy 0.74          
Testing in progress @ step 3039 loss 0.933452 accuracy 0.67          
Training in progress @ step 3059 loss 0.728232 accuracy 0.66          
Testing in progress @ step 3059 loss 0.609125 accuracy 0.72          
Training in progress @ step 3079 loss 0.583779 accuracy 0.76          
Testing in progress @ step 3079 loss 0.693111 accuracy 0.7          
Training in progress @ step 3099 loss 0.969401 accuracy 0.46          
Testing in progress @ step 3099 loss 0.833739 accuracy 0.57          
saved @ weights/toynet-3099
Training in progress @ step 3119 loss 0.588207 accuracy 0.82          
Testing in progress @ step 3119 loss 0.813724 accuracy 0.64          
Training in progress @ step 3139 loss 0.535594 accuracy 0.76          
Testing in progress @ step 3139 loss 0.588565 accuracy 0.76          
Training in progress @ step 3159 loss 0.678258 accuracy 0.7          
Testing in progress @ step 3159 loss 0.591031 accuracy 0.71          
Training in progress @ step 3179 loss 0.690407 accuracy 0.74          
Testing in progress @ step 3179 loss 0.996247 accuracy 0.61          
Training in progress @ step 3199 loss 0.545951 accuracy 0.76          
Testing in progress @ step 3199 loss 0.869521 accuracy 0.69          
saved @ weights/toynet-3199
Training in progress @ step 3219 loss 0.611411 accuracy 0.7          
Testing in progress @ step 3219 loss 0.747814 accuracy 0.73          
Training in progress @ step 3239 loss 0.500571 accuracy 0.76          
Testing in progress @ step 3239 loss 0.841545 accuracy 0.58          
Training in progress @ step 3259 loss 0.661496 accuracy 0.74          
Testing in progress @ step 3259 loss 0.876797 accuracy 0.62          
Training in progress @ step 3279 loss 0.773342 accuracy 0.64          
Testing in progress @ step 3279 loss 0.769359 accuracy 0.68          
Training in progress @ step 3299 loss 0.904071 accuracy 0.5          
Testing in progress @ step 3299 loss 0.708336 accuracy 0.69          
saved @ weights/toynet-3299
Training in progress @ step 3319 loss 0.625595 accuracy 0.7          
Testing in progress @ step 3319 loss 0.843951 accuracy 0.6          
Training in progress @ step 3339 loss 0.575792 accuracy 0.74          
Testing in progress @ step 3339 loss 0.8904 accuracy 0.63          
Training in progress @ step 3359 loss 0.754028 accuracy 0.66          
Testing in progress @ step 3359 loss 0.758322 accuracy 0.65          
Training in progress @ step 3379 loss 0.661254 accuracy 0.76          
Testing in progress @ step 3379 loss 0.747814 accuracy 0.64          
Training in progress @ step 3399 loss 0.915007 accuracy 0.52          
Testing in progress @ step 3399 loss 0.924655 accuracy 0.57          
saved @ weights/toynet-3399
Training in progress @ step 3419 loss 0.592136 accuracy 0.7          
Testing in progress @ step 3419 loss 0.688503 accuracy 0.66          
Training in progress @ step 3439 loss 0.53446 accuracy 0.72          
Testing in progress @ step 3439 loss 0.713104 accuracy 0.62          
Training in progress @ step 3459 loss 0.641942 accuracy 0.72          
Testing in progress @ step 3459 loss 0.793349 accuracy 0.66          
Training in progress @ step 3479 loss 0.651127 accuracy 0.76          
Testing in progress @ step 3479 loss 0.697957 accuracy 0.7          
Training in progress @ step 3499 loss 0.811335 accuracy 0.56          
Testing in progress @ step 3499 loss 0.717807 accuracy 0.71          
saved @ weights/toynet-3499
Training in progress @ step 3519 loss 0.619678 accuracy 0.7          
Testing in progress @ step 3519 loss 0.823851 accuracy 0.66          
Training in progress @ step 3539 loss 0.858907 accuracy 0.66          
Testing in progress @ step 3539 loss 0.833918 accuracy 0.65          
Training in progress @ step 3559 loss 0.738354 accuracy 0.6          
Testing in progress @ step 3559 loss 0.676696 accuracy 0.7          
Training in progress @ step 3579 loss 0.703173 accuracy 0.74          
Testing in progress @ step 3579 loss 1.09339 accuracy 0.67          
Training in progress @ step 3599 loss 0.604465 accuracy 0.76          
Testing in progress @ step 3599 loss 0.649062 accuracy 0.68          
saved @ weights/toynet-3599
Training in progress @ step 3619 loss 0.566989 accuracy 0.76          
Testing in progress @ step 3619 loss 0.73983 accuracy 0.67          
Training in progress @ step 3639 loss 0.565764 accuracy 0.76          
Testing in progress @ step 3639 loss 0.97306 accuracy 0.66          
Training in progress @ step 3659 loss 0.609621 accuracy 0.74          
Testing in progress @ step 3659 loss 0.661985 accuracy 0.72          
Training in progress @ step 3679 loss 0.634706 accuracy 0.7          
Testing in progress @ step 3679 loss 0.828382 accuracy 0.64          
Training in progress @ step 3699 loss 0.530048 accuracy 0.78          
Testing in progress @ step 3699 loss 1.06915 accuracy 0.65          
saved @ weights/toynet-3699
Training in progress @ step 3719 loss 0.608648 accuracy 0.82          
Testing in progress @ step 3719 loss 0.802318 accuracy 0.66          
Training in progress @ step 3739 loss 0.707695 accuracy 0.64          
Testing in progress @ step 3739 loss 0.796944 accuracy 0.75          
Training in progress @ step 3759 loss 0.629873 accuracy 0.74          
Testing in progress @ step 3759 loss 0.786761 accuracy 0.59          
Training in progress @ step 3779 loss 0.699369 accuracy 0.68          
Testing in progress @ step 3779 loss 0.820317 accuracy 0.65          
Training in progress @ step 3799 loss 0.496323 accuracy 0.86          
Testing in progress @ step 3799 loss 0.630245 accuracy 0.67          
saved @ weights/toynet-3799
Training in progress @ step 3819 loss 0.558216 accuracy 0.74          
Testing in progress @ step 3819 loss 0.658045 accuracy 0.69          
Training in progress @ step 3839 loss 0.521911 accuracy 0.76          
Testing in progress @ step 3839 loss 0.706592 accuracy 0.75          
Training in progress @ step 3859 loss 0.705313 accuracy 0.58          
Testing in progress @ step 3859 loss 1.0322 accuracy 0.61          
Training in progress @ step 3879 loss 0.669163 accuracy 0.74          
Testing in progress @ step 3879 loss 0.74675 accuracy 0.67          
Training in progress @ step 3899 loss 0.778846 accuracy 0.64          
Testing in progress @ step 3899 loss 1.09875 accuracy 0.65          
saved @ weights/toynet-3899
Training in progress @ step 3919 loss 0.562154 accuracy 0.78          
Testing in progress @ step 3919 loss 0.528436 accuracy 0.76          
Training in progress @ step 3939 loss 0.527017 accuracy 0.76          
Testing in progress @ step 3939 loss 0.777258 accuracy 0.67          
Training in progress @ step 3959 loss 0.644141 accuracy 0.74          
Testing in progress @ step 3959 loss 0.955519 accuracy 0.63          
Training in progress @ step 3979 loss 0.483887 accuracy 0.82          
Testing in progress @ step 3979 loss 0.741936 accuracy 0.69          
Training in progress @ step 3999 loss 0.801905 accuracy 0.56          
Testing in progress @ step 3999 loss 0.740641 accuracy 0.68          
saved @ weights/toynet-3999
Training in progress @ step 4019 loss 0.534196 accuracy 0.76          
Testing in progress @ step 4019 loss 0.836735 accuracy 0.61          
Training in progress @ step 4039 loss 0.708263 accuracy 0.64          
Testing in progress @ step 4039 loss 0.865541 accuracy 0.76          
Training in progress @ step 4059 loss 0.577173 accuracy 0.72          
Testing in progress @ step 4059 loss 0.557551 accuracy 0.73          
Training in progress @ step 4079 loss 0.658289 accuracy 0.7          
Testing in progress @ step 4079 loss 0.737281 accuracy 0.71          
Training in progress @ step 4099 loss 0.764987 accuracy 0.58          
Testing in progress @ step 4099 loss 0.755877 accuracy 0.6          
saved @ weights/toynet-4099
Training in progress @ step 4119 loss 0.559188 accuracy 0.82          
Testing in progress @ step 4119 loss 0.798659 accuracy 0.66          
Training in progress @ step 4139 loss 0.498029 accuracy 0.78          
Testing in progress @ step 4139 loss 0.564819 accuracy 0.75          
Training in progress @ step 4159 loss 0.612597 accuracy 0.7          
Testing in progress @ step 4159 loss 0.571949 accuracy 0.77          
Training in progress @ step 4179 loss 0.538559 accuracy 0.8          
Testing in progress @ step 4179 loss 0.945541 accuracy 0.66          
Training in progress @ step 4199 loss 0.809389 accuracy 0.6          
Testing in progress @ step 4199 loss 0.916501 accuracy 0.66          
saved @ weights/toynet-4199
Training in progress @ step 4219 loss 0.552245 accuracy 0.8          
Testing in progress @ step 4219 loss 0.71138 accuracy 0.68          
Training in progress @ step 4239 loss 0.598316 accuracy 0.78          
Testing in progress @ step 4239 loss 0.804888 accuracy 0.59          
Training in progress @ step 4259 loss 0.574028 accuracy 0.72          
Testing in progress @ step 4259 loss 1.17863 accuracy 0.66          
Training in progress @ step 4279 loss 0.507018 accuracy 0.82          
Testing in progress @ step 4279 loss 0.717412 accuracy 0.72          
Training in progress @ step 4299 loss 0.725069 accuracy 0.54          
Testing in progress @ step 4299 loss 0.763786 accuracy 0.68          
saved @ weights/toynet-4299
Training in progress @ step 4319 loss 0.547566 accuracy 0.7          
Testing in progress @ step 4319 loss 0.897501 accuracy 0.62          
Training in progress @ step 4339 loss 0.437541 accuracy 0.82          
Testing in progress @ step 4339 loss 0.861329 accuracy 0.69          
Training in progress @ step 4359 loss 0.587879 accuracy 0.76          
Testing in progress @ step 4359 loss 0.747539 accuracy 0.68          
Training in progress @ step 4379 loss 0.502393 accuracy 0.76          
Testing in progress @ step 4379 loss 0.749756 accuracy 0.72          
Training in progress @ step 4399 loss 0.777657 accuracy 0.62          
Testing in progress @ step 4399 loss 1.01437 accuracy 0.63          
saved @ weights/toynet-4399
Training in progress @ step 4419 loss 0.514751 accuracy 0.84          
Testing in progress @ step 4419 loss 0.777094 accuracy 0.66          
Training in progress @ step 4439 loss 0.512706 accuracy 0.76          
Testing in progress @ step 4439 loss 0.65704 accuracy 0.67          
Training in progress @ step 4459 loss 0.702033 accuracy 0.64          
Testing in progress @ step 4459 loss 0.709192 accuracy 0.67          
Training in progress @ step 4479 loss 0.643489 accuracy 0.74          
Testing in progress @ step 4479 loss 0.710084 accuracy 0.71          
Training in progress @ step 4499 loss 0.472949 accuracy 0.84          
Testing in progress @ step 4499 loss 0.637643 accuracy 0.73          
saved @ weights/toynet-4499
Training in progress @ step 4519 loss 0.526931 accuracy 0.78          
Testing in progress @ step 4519 loss 0.802738 accuracy 0.66          
Training in progress @ step 4539 loss 0.71399 accuracy 0.66          
Testing in progress @ step 4539 loss 0.725557 accuracy 0.68          
Training in progress @ step 4559 loss 0.59562 accuracy 0.72          
Testing in progress @ step 4559 loss 0.768135 accuracy 0.7          
Training in progress @ step 4579 loss 0.513815 accuracy 0.78          
Testing in progress @ step 4579 loss 1.30597 accuracy 0.69          
Training in progress @ step 4599 loss 0.846219 accuracy 0.58          
Testing in progress @ step 4599 loss 0.708973 accuracy 0.69          
saved @ weights/toynet-4599
Training in progress @ step 4619 loss 0.545314 accuracy 0.72          
Testing in progress @ step 4619 loss 0.704354 accuracy 0.71          
Training in progress @ step 4639 loss 0.508829 accuracy 0.74          
Testing in progress @ step 4639 loss 0.98429 accuracy 0.69          
Training in progress @ step 4659 loss 0.644264 accuracy 0.68          
Testing in progress @ step 4659 loss 0.600745 accuracy 0.74          
Training in progress @ step 4679 loss 0.46995 accuracy 0.82          
Testing in progress @ step 4679 loss 0.820408 accuracy 0.61          
Training in progress @ step 4699 loss 0.732839 accuracy 0.62          
Testing in progress @ step 4699 loss 0.740484 accuracy 0.67          
saved @ weights/toynet-4699
Training in progress @ step 4719 loss 0.495116 accuracy 0.8          
Testing in progress @ step 4719 loss 0.878607 accuracy 0.64          
Training in progress @ step 4739 loss 0.458679 accuracy 0.8          
Testing in progress @ step 4739 loss 0.842409 accuracy 0.71          
Training in progress @ step 4759 loss 0.54042 accuracy 0.76          
Testing in progress @ step 4759 loss 1.25367 accuracy 0.64          
Training in progress @ step 4779 loss 0.484868 accuracy 0.84          
Testing in progress @ step 4779 loss 0.915994 accuracy 0.63          
Training in progress @ step 4799 loss 0.696491 accuracy 0.68          
Testing in progress @ step 4799 loss 0.734606 accuracy 0.72          
saved @ weights/toynet-4799
Training in progress @ step 4819 loss 0.495629 accuracy 0.82          
Testing in progress @ step 4819 loss 0.731098 accuracy 0.64          
Training in progress @ step 4839 loss 0.513645 accuracy 0.82          
Testing in progress @ step 4839 loss 0.820735 accuracy 0.73          
Training in progress @ step 4859 loss 0.556325 accuracy 0.74          
Testing in progress @ step 4859 loss 0.983378 accuracy 0.65          
Training in progress @ step 4879 loss 0.538882 accuracy 0.8          
Testing in progress @ step 4879 loss 0.885603 accuracy 0.68          
Training in progress @ step 4899 loss 0.801503 accuracy 0.56          
Testing in progress @ step 4899 loss 1.21059 accuracy 0.65          
saved @ weights/toynet-4899
Training in progress @ step 4919 loss 0.482372 accuracy 0.78          
Testing in progress @ step 4919 loss 0.521534 accuracy 0.76          
Training in progress @ step 4939 loss 0.709935 accuracy 0.7          
Testing in progress @ step 4939 loss 0.673117 accuracy 0.7          
Training in progress @ step 4959 loss 0.614147 accuracy 0.68          
Testing in progress @ step 4959 loss 0.833616 accuracy 0.65          
Training in progress @ step 4979 loss 0.623204 accuracy 0.82          
Testing in progress @ step 4979 loss 0.713888 accuracy 0.66          
Training in progress @ step 4999 loss 0.62346 accuracy 0.7          
Testing in progress @ step 4999 loss 0.692974 accuracy 0.74          
saved @ weights/toynet-4999

Run `tensorboard --logdir=log` in terminal to see the results.
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Checking-log-on-the-tensorboard">Checking log on the tensorboard<a class="anchor-link" href="#Checking-log-on-the-tensorboard">&#182;</a></h2><p>As the last line above says you can visualize your log using tensorboard. This command</p>

<pre><code>tensorboard --logdir=log</code></pre>
<p>on the terminal instantiates the tensorboard server and tells the localhost address to access through your web-browser. You can certainly <a href="https://www.ssh.com/ssh/tunneling/">ssh-tunnel</a> to access the <em>localhost</em> of your remote machine to check it on your local machine's web-browser as well. For the above training, here's the screenshot of the loss and accuracy curve for train and test samples where the <em>blue</em> line represents metric measured on the training set and <em>orange</em> line is for the same on the test sample.</p>
<p><img src="theme/img/tutorial05-training-classification-loss.png" alt="loss"></p>
<p><img src="theme/img/tutorial05-training-classification-accuracy.png" alt="accuracy"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This notebook covered training convolutional neural networks to perform image classification of 5 LArTPC particles using a practice files. We encourage you to design your own network and train on our <a href="http://deeplearnphysics.org/DataChallenge">public dataset</a>! We provide 50,000 entries of 5 particle images (10,000 per particle) for training and separate 40,000 for testing your network. When you are confident, try our <em>data challenge</em>, yet another set of 40,000 events without <em>answers</em> (i.e. no <code>particle</code> information). Share your awesome result in the CSV format to <a href="contact@deeplearnphysics.org">us</a> with your network architecture made available on a github repository.</p>

</div>
</div>
</div>
 


<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: 'center'," +
        "    displayIndent: '0em'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['$','$'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        " linebreaks: { automatic: true, width: '95% container' }, " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
        "    } " +
        "}); ";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>

  </div>
  <div class="tag-cloud">
    <p>
      <a href="http://deeplearnphysics.org/Blog/tag/tutorial.html">tutorial</a>
    </p>
  </div>



</article>

    <footer>
<p>
  &copy; DeepLearnPhysics 2017 - This work is licensed under a <a rel="license" href="https://opensource.org/licenses/MIT">MIT License</a>
</p>
<p>
</p>    </footer>
  </main>





<script type="application/ld+json">
{
  "@context" : "http://schema.org",
  "@type" : "Blog",
  "name": " DeepLearnPhysics Blog ",
  "url" : "http://deeplearnphysics.org/Blog",
  "image": "profile.png",
  "description": "description!"
}
</script>
</body>
</html>